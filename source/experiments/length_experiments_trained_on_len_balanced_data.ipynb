{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from config import Config\n",
    "from experiments_utils import *\n",
    "import pickle as pkl\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV containing comments and features from all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feats_file = Config.ALL_FEATURES_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feats_df = pd.read_csv(training_feats_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feats_df['comment_len'] = training_feats_df['pp_comment_text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOCC_df contains instances of annotated SOCC with the new annotation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOCC_df = training_feats_df[training_feats_df['source'] == 'SOCC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feats_df = training_feats_df[['pp_comment_text', 'constructive', 'source',\n",
    "       'has_conjunctions_and_connectives', 'has_stance_adverbials',\n",
    "       'has_reasoning_verbs', 'has_modals', 'has_shell_nouns', 'length',\n",
    "       'average_word_length', 'readability_score', 'personal_exp_score',\n",
    "       'named_entity_count', 'nSents', 'avg_words_per_sent', \n",
    "       'SEVERE_TOXICITY:probability', 'SEXUALLY_EXPLICIT:probability',\n",
    "       'TOXICITY:probability', 'TOXICITY_IDENTITY_HATE:probability',\n",
    "       'TOXICITY_INSULT:probability', 'TOXICITY_OBSCENE:probability',\n",
    "       'TOXICITY_THREAT:probability', 'ATTACK_ON_AUTHOR:probability',\n",
    "       'ATTACK_ON_COMMENTER:probability', 'ATTACK_ON_PUBLISHER:probability',\n",
    "       'INCOHERENT:probability', 'INFLAMMATORY:probability',\n",
    "       'LIKELY_TO_REJECT:probability', 'OBSCENE:probability',\n",
    "       'OFF_TOPIC:probability', 'SPAM:probability',\n",
    "       'UNSUBSTANTIAL:probability', 'comment_len']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all_SOCC_df contains all instances of annotated SOCC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_SOCC_df = training_feats_df[training_feats_df['source'].str.endswith('SOCC')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feats = ['text_feats']\n",
    "\n",
    "len_dependent_feats = ['length_feats',\n",
    "             'argumentation_feats',\n",
    "             'COMMENTIQ_feats',\n",
    "             'named_entity_feats']\n",
    "\n",
    "crowd_annotated_feats = ['constructiveness_chars_feats',\n",
    "                         'non_constructiveness_chars_feats',\n",
    "                         'toxicity_chars_feats']\n",
    "\n",
    "perspective_feats = ['perspective_content_value_feats',\n",
    "                     'perspective_aggressiveness_feats',\n",
    "                     'perspecitive_toxicity_feats']\n",
    "\n",
    "all_feats =  text_feats + len_dependent_feats + perspective_feats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_results(avg_results_dict):\n",
    "    for (test_subset, res) in avg_results_dict.items():\n",
    "        raw_html = '<h2>' + test_subset + '</h2>'\n",
    "        display(HTML(raw_html))\n",
    "        df = pd.DataFrame.from_dict(res, orient='index')\n",
    "                           #,columns=['Recall', 'Precision', 'F-score', 'Dummy'])\n",
    "        display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only length dependent feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  1\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10446\n",
      "Test samples:  2589\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4775 \tConstructive ( 2843 ) \tNon constructive ( 1932 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1228 \tConstructive ( 1041 ) \tNon constructive ( 187 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1168 \tConstructive ( 712 ) \tNon constructive ( 456 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  297 \tConstructive ( 251 ) \tNon constructive ( 46 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats']\n",
      "Size of the training data:  4775 \tConstructive ( 2843 ) \tNon constructive ( 1932 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2589 \tConstructive ( 1316 ) \tNon constructive ( 1273 )\n",
      "Accuracy:  0.9208188489764387\n",
      "Precision-recall for each class:  (array([0.92537313, 0.91641337]), array([0.91459627, 0.92697925]), array([0.91995314, 0.92166603]), array([1288, 1301]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.93      0.92      1273\n",
      "    constructive       0.93      0.92      0.92      1316\n",
      "\n",
      "     avg / total       0.92      0.92      0.92      2589\n",
      "\n",
      "Results: \n",
      "macro_average => (0.9208932540942703, 0.9207877600126038, 0.9208095865542587, None)\n",
      "weighted_average => (0.9208707595237632, 0.9208188489764387, 0.9208138869645566, None)\n",
      "micro_average => (0.9208188489764387, 0.9208188489764387, 0.9208188489764387, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1168 \tConstructive ( 712 ) \tNon constructive ( 456 )\n",
      "Accuracy:  0.8544520547945206\n",
      "Precision-recall for each class:  (array([0.83114035, 0.86938202]), array([0.8029661 , 0.88936782]), array([0.81681034, 0.87926136]), array([472, 696]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.80      0.83      0.82       456\n",
      "    constructive       0.89      0.87      0.88       712\n",
      "\n",
      "     avg / total       0.86      0.85      0.85      1168\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8502611866745515, 0.8461669588934346, 0.8480358542319748, None)\n",
      "weighted_average => (0.8539281962795244, 0.8544520547945206, 0.8540243080903508, None)\n",
      "micro_average => (0.8544520547945206, 0.8544520547945206, 0.8544520547945207, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  297 \tConstructive ( 251 ) \tNon constructive ( 46 )\n",
      "Accuracy:  0.47474747474747475\n",
      "Precision-recall for each class:  (array([0.        , 0.56175299]), array([0.       , 0.7540107]), array([0.        , 0.64383562]), array([110, 187]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        46\n",
      "    constructive       0.75      0.56      0.64       251\n",
      "\n",
      "     avg / total       0.64      0.47      0.54       297\n",
      "\n",
      "Results: \n",
      "macro_average => (0.28087649402390436, 0.3770053475935829, 0.3219178082191781, None)\n",
      "weighted_average => (0.3536963258078796, 0.47474747474747475, 0.4053779807204465, None)\n",
      "micro_average => (0.47474747474747475, 0.47474747474747475, 0.47474747474747475, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  2\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10404\n",
      "Test samples:  2631\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4726 \tConstructive ( 2840 ) \tNon constructive ( 1886 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1219 \tConstructive ( 1029 ) \tNon constructive ( 190 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1217 \tConstructive ( 715 ) \tNon constructive ( 502 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  306 \tConstructive ( 263 ) \tNon constructive ( 43 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats']\n",
      "Size of the training data:  4726 \tConstructive ( 2840 ) \tNon constructive ( 1886 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2631 \tConstructive ( 1306 ) \tNon constructive ( 1325 )\n",
      "Accuracy:  0.9171417711896618\n",
      "Precision-recall for each class:  (array([0.91320755, 0.92113323]), array([0.92155369, 0.91274659]), array([0.91736164, 0.91692073]), array([1313, 1318]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.92      0.91      0.92      1325\n",
      "    constructive       0.91      0.92      0.92      1306\n",
      "\n",
      "     avg / total       0.92      0.92      0.92      2631\n",
      "\n",
      "Results: \n",
      "macro_average => (0.9171703892051201, 0.9171501397834425, 0.9171411846557813, None)\n",
      "weighted_average => (0.9171779202618198, 0.9171417711896618, 0.9171407657030095, None)\n",
      "micro_average => (0.9171417711896618, 0.9171417711896618, 0.9171417711896618, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1217 \tConstructive ( 715 ) \tNon constructive ( 502 )\n",
      "Accuracy:  0.8603122432210353\n",
      "Precision-recall for each class:  (array([0.812749  , 0.89370629]), array([0.84297521, 0.87175989]), array([0.82758621, 0.88259669]), array([484, 733]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.84      0.81      0.83       502\n",
      "    constructive       0.87      0.89      0.88       715\n",
      "\n",
      "     avg / total       0.86      0.86      0.86      1217\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8532276488451788, 0.8573675487355259, 0.8550914459897123, None)\n",
      "weighted_average => (0.8615096394535746, 0.8603122432210353, 0.8607190585897099, None)\n",
      "micro_average => (0.8603122432210353, 0.8603122432210353, 0.8603122432210354, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  306 \tConstructive ( 263 ) \tNon constructive ( 43 )\n",
      "Accuracy:  0.5261437908496732\n",
      "Precision-recall for each class:  (array([0.02325581, 0.60836502]), array([0.00961538, 0.79207921]), array([0.01360544, 0.68817204]), array([104, 202]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.01      0.02      0.01        43\n",
      "    constructive       0.79      0.61      0.69       263\n",
      "\n",
      "     avg / total       0.68      0.53      0.59       306\n",
      "\n",
      "Results: \n",
      "macro_average => (0.3158104164824476, 0.40084729626808835, 0.3508887425938117, None)\n",
      "weighted_average => (0.4095043741551208, 0.5261437908496732, 0.45890757736786464, None)\n",
      "micro_average => (0.5261437908496732, 0.5261437908496732, 0.5261437908496732, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  3\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10436\n",
      "Test samples:  2599\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4765 \tConstructive ( 2866 ) \tNon constructive ( 1899 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1223 \tConstructive ( 1048 ) \tNon constructive ( 175 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1178 \tConstructive ( 689 ) \tNon constructive ( 489 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  302 \tConstructive ( 244 ) \tNon constructive ( 58 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats']\n",
      "Size of the training data:  4765 \tConstructive ( 2866 ) \tNon constructive ( 1899 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2599 \tConstructive ( 1253 ) \tNon constructive ( 1346 )\n",
      "Accuracy:  0.9195844555598307\n",
      "Precision-recall for each class:  (array([0.90564636, 0.93455706]), array([0.93697156, 0.90215716]), array([0.92104269, 0.91807134]), array([1301, 1298]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.94      0.91      0.92      1346\n",
      "    constructive       0.90      0.93      0.92      1253\n",
      "\n",
      "     avg / total       0.92      0.92      0.92      2599\n",
      "\n",
      "Results: \n",
      "macro_average => (0.9201017113163178, 0.9195643626036154, 0.9195570172041543, None)\n",
      "weighted_average => (0.9200850256467538, 0.9195844555598307, 0.9195587321013841, None)\n",
      "micro_average => (0.9195844555598307, 0.9195844555598307, 0.9195844555598307, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1178 \tConstructive ( 689 ) \tNon constructive ( 489 )\n",
      "Accuracy:  0.8539898132427843\n",
      "Precision-recall for each class:  (array([0.78527607, 0.90275762]), array([0.85144124, 0.85557084]), array([0.81702128, 0.87853107]), array([451, 727]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.85      0.79      0.82       489\n",
      "    constructive       0.86      0.90      0.88       689\n",
      "\n",
      "     avg / total       0.85      0.85      0.85      1178\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8440168466791919, 0.8535060403748966, 0.8477761750210362, None)\n",
      "weighted_average => (0.8577795405369495, 0.8539898132427843, 0.8549819067403743, None)\n",
      "micro_average => (0.8539898132427843, 0.8539898132427843, 0.8539898132427843, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  302 \tConstructive ( 244 ) \tNon constructive ( 58 )\n",
      "Accuracy:  0.5364238410596026\n",
      "Precision-recall for each class:  (array([0.        , 0.66393443]), array([0.        , 0.73636364]), array([0.        , 0.69827586]), array([ 82, 220]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        58\n",
      "    constructive       0.74      0.66      0.70       244\n",
      "\n",
      "     avg / total       0.59      0.54      0.56       302\n",
      "\n",
      "Results: \n",
      "macro_average => (0.3319672131147541, 0.36818181818181817, 0.34913793103448276, None)\n",
      "weighted_average => (0.4836608402996417, 0.5364238410596026, 0.5086777803151404, None)\n",
      "micro_average => (0.5364238410596026, 0.5364238410596026, 0.5364238410596026, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  4\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10418\n",
      "Test samples:  2617\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4765 \tConstructive ( 2862 ) \tNon constructive ( 1903 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1203 \tConstructive ( 1020 ) \tNon constructive ( 183 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1178 \tConstructive ( 693 ) \tNon constructive ( 485 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  322 \tConstructive ( 272 ) \tNon constructive ( 50 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats']\n",
      "Size of the training data:  4765 \tConstructive ( 2862 ) \tNon constructive ( 1903 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2617 \tConstructive ( 1264 ) \tNon constructive ( 1353 )\n",
      "Accuracy:  0.9109667558272831\n",
      "Precision-recall for each class:  (array([0.91869919, 0.90268987]), array([0.90995608, 0.91207034]), array([0.91430673, 0.90735586]), array([1366, 1251]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.92      0.91      1353\n",
      "    constructive       0.91      0.90      0.91      1264\n",
      "\n",
      "     avg / total       0.91      0.91      0.91      2617\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: \n",
      "macro_average => (0.9106945302047957, 0.9110132099298599, 0.9108312976133636, None)\n",
      "weighted_average => (0.9110462824136278, 0.9109667558272831, 0.9109840201094495, None)\n",
      "micro_average => (0.9109667558272831, 0.9109667558272831, 0.9109667558272831, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1178 \tConstructive ( 693 ) \tNon constructive ( 485 )\n",
      "Accuracy:  0.8353140916808149\n",
      "Precision-recall for each class:  (array([0.81237113, 0.85137085]), array([0.79275654, 0.86637298]), array([0.80244399, 0.8588064 ]), array([497, 681]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.79      0.81      0.80       485\n",
      "    constructive       0.87      0.85      0.86       693\n",
      "\n",
      "     avg / total       0.84      0.84      0.84      1178\n",
      "\n",
      "Results: \n",
      "macro_average => (0.831870992695735, 0.8295647600729191, 0.8306251982556467, None)\n",
      "weighted_average => (0.8349168110286903, 0.8353140916808149, 0.8350270165731516, None)\n",
      "micro_average => (0.8353140916808149, 0.8353140916808149, 0.8353140916808149, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  322 \tConstructive ( 272 ) \tNon constructive ( 50 )\n",
      "Accuracy:  0.46273291925465837\n",
      "Precision-recall for each class:  (array([0.        , 0.54779412]), array([0.        , 0.74874372]), array([0.        , 0.63269639]), array([123, 199]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        50\n",
      "    constructive       0.75      0.55      0.63       272\n",
      "\n",
      "     avg / total       0.63      0.46      0.53       322\n",
      "\n",
      "Results: \n",
      "macro_average => (0.27389705882352944, 0.3743718592964824, 0.3163481953290871, None)\n",
      "weighted_average => (0.33854356960175375, 0.46273291925465837, 0.3910142290092443, None)\n",
      "micro_average => (0.46273291925465837, 0.46273291925465837, 0.46273291925465837, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  5\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10457\n",
      "Test samples:  2578\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4762 \tConstructive ( 2843 ) \tNon constructive ( 1919 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1206 \tConstructive ( 1025 ) \tNon constructive ( 181 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1181 \tConstructive ( 712 ) \tNon constructive ( 469 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  319 \tConstructive ( 267 ) \tNon constructive ( 52 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats']\n",
      "Size of the training data:  4762 \tConstructive ( 2843 ) \tNon constructive ( 1919 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2578 \tConstructive ( 1318 ) \tNon constructive ( 1260 )\n",
      "Accuracy:  0.917377812257564\n",
      "Precision-recall for each class:  (array([0.90793651, 0.92640364]), array([0.92183723, 0.91323859]), array([0.91483407, 0.91977401]), array([1241, 1337]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.92      0.91      0.91      1260\n",
      "    constructive       0.91      0.93      0.92      1318\n",
      "\n",
      "     avg / total       0.92      0.92      0.92      2578\n",
      "\n",
      "Results: \n",
      "macro_average => (0.9171700749090734, 0.917537910954384, 0.9173040388364428, None)\n",
      "weighted_average => (0.9175139160376096, 0.917377812257564, 0.9173960160887498, None)\n",
      "micro_average => (0.917377812257564, 0.917377812257564, 0.917377812257564, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1181 \tConstructive ( 712 ) \tNon constructive ( 469 )\n",
      "Accuracy:  0.8518204911092294\n",
      "Precision-recall for each class:  (array([0.80383795, 0.88342697]), array([0.81956522, 0.87239945]), array([0.8116254 , 0.87787858]), array([460, 721]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.82      0.80      0.81       469\n",
      "    constructive       0.87      0.88      0.88       712\n",
      "\n",
      "     avg / total       0.85      0.85      0.85      1181\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8436324596919096, 0.8459823313031418, 0.8447519900364844, None)\n",
      "weighted_average => (0.8524270119549568, 0.8518204911092294, 0.8520729375761132, None)\n",
      "micro_average => (0.8518204911092294, 0.8518204911092294, 0.8518204911092294, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  319 \tConstructive ( 267 ) \tNon constructive ( 52 )\n",
      "Accuracy:  0.5329153605015674\n",
      "Precision-recall for each class:  (array([0.        , 0.63670412]), array([0.        , 0.76576577]), array([0.        , 0.69529652]), array([ 97, 222]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        52\n",
      "    constructive       0.77      0.64      0.70       267\n",
      "\n",
      "     avg / total       0.64      0.53      0.58       319\n",
      "\n",
      "Results: \n",
      "macro_average => (0.31835205992509363, 0.38288288288288286, 0.3476482617586912, None)\n",
      "weighted_average => (0.4430981649114156, 0.5329153605015674, 0.48387406965786484, None)\n",
      "micro_average => (0.5329153605015674, 0.5329153605015674, 0.5329153605015674, None)\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "feature_set = len_dependent_feats\n",
    "avg_results_len_dict = run_n_experiments(all_SOCC_df, feature_set, train_balanced = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>test_balanced</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.846518</td>\n",
       "      <td>0.845256</td>\n",
       "      <td>0.844602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.851178</td>\n",
       "      <td>0.851178</td>\n",
       "      <td>0.851178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.851178</td>\n",
       "      <td>0.851365</td>\n",
       "      <td>0.852112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_all</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.917211</td>\n",
       "      <td>0.917129</td>\n",
       "      <td>0.917206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.917178</td>\n",
       "      <td>0.917178</td>\n",
       "      <td>0.917178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.917178</td>\n",
       "      <td>0.917179</td>\n",
       "      <td>0.917339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_hard</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.380658</td>\n",
       "      <td>0.337188</td>\n",
       "      <td>0.304181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.506593</td>\n",
       "      <td>0.506593</td>\n",
       "      <td>0.506593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.506593</td>\n",
       "      <td>0.449570</td>\n",
       "      <td>0.405701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print_results(avg_results_len_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only perspective features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  1\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10409\n",
      "Test samples:  2626\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4731 \tConstructive ( 2840 ) \tNon constructive ( 1891 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1230 \tConstructive ( 1040 ) \tNon constructive ( 190 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1212 \tConstructive ( 715 ) \tNon constructive ( 497 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  295 \tConstructive ( 252 ) \tNon constructive ( 43 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4731 \tConstructive ( 2840 ) \tNon constructive ( 1891 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2626 \tConstructive ( 1289 ) \tNon constructive ( 1337 )\n",
      "Accuracy:  0.8846153846153846\n",
      "Precision-recall for each class:  (array([0.85564697, 0.91466253]), array([0.9122807 , 0.85932945]), array([0.88305673, 0.88613303]), array([1254, 1372]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.86      0.88      1337\n",
      "    constructive       0.86      0.91      0.89      1289\n",
      "\n",
      "     avg / total       0.89      0.88      0.88      2626\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8851547499612682, 0.8858050739092629, 0.8845948837729423, None)\n",
      "weighted_average => (0.8864806897698989, 0.8846153846153846, 0.8846640008988907, None)\n",
      "micro_average => (0.8846153846153846, 0.8846153846153846, 0.8846153846153846, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1212 \tConstructive ( 715 ) \tNon constructive ( 497 )\n",
      "Accuracy:  0.7772277227722773\n",
      "Precision-recall for each class:  (array([0.65191147, 0.86433566]), array([0.7695962 , 0.78128951]), array([0.70588235, 0.82071713]), array([421, 791]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.77      0.65      0.71       497\n",
      "    constructive       0.78      0.86      0.82       715\n",
      "\n",
      "     avg / total       0.78      0.78      0.77      1212\n",
      "\n",
      "Results: \n",
      "macro_average => (0.7581235665742708, 0.7754428532390822, 0.76329974220764, None)\n",
      "weighted_average => (0.7905480518644652, 0.7772277227722773, 0.7808281531223195, None)\n",
      "micro_average => (0.7772277227722773, 0.7772277227722773, 0.7772277227722773, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  295 \tConstructive ( 252 ) \tNon constructive ( 43 )\n",
      "Accuracy:  0.6474576271186441\n",
      "Precision-recall for each class:  (array([0.25581395, 0.71428571]), array([0.13253012, 0.8490566 ]), array([0.17460317, 0.77586207]), array([ 83, 212]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.13      0.26      0.17        43\n",
      "    constructive       0.85      0.71      0.78       252\n",
      "\n",
      "     avg / total       0.74      0.65      0.69       295\n",
      "\n",
      "Results: \n",
      "macro_average => (0.4850498338870432, 0.4907933621277563, 0.47523262178434594, None)\n",
      "weighted_average => (0.5852919646376485, 0.6474576271186441, 0.6066943122466208, None)\n",
      "micro_average => (0.6474576271186441, 0.6474576271186441, 0.6474576271186441, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  2\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10382\n",
      "Test samples:  2653\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4721 \tConstructive ( 2820 ) \tNon constructive ( 1901 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1210 \tConstructive ( 1025 ) \tNon constructive ( 185 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1222 \tConstructive ( 735 ) \tNon constructive ( 487 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  315 \tConstructive ( 267 ) \tNon constructive ( 48 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4721 \tConstructive ( 2820 ) \tNon constructive ( 1901 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2653 \tConstructive ( 1318 ) \tNon constructive ( 1335 )\n",
      "Accuracy:  0.868450810403317\n",
      "Precision-recall for each class:  (array([0.85692884, 0.8801214 ]), array([0.87864823, 0.85862324]), array([0.86765264, 0.86923942]), array([1302, 1351]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.88      0.86      0.87      1335\n",
      "    constructive       0.86      0.88      0.87      1318\n",
      "\n",
      "     avg / total       0.87      0.87      0.87      2653\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8685251175029696, 0.8686357377649372, 0.868446025541076, None)\n",
      "weighted_average => (0.8687392967902033, 0.868450810403317, 0.8684606791816892, None)\n",
      "micro_average => (0.868450810403317, 0.868450810403317, 0.868450810403317, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1222 \tConstructive ( 735 ) \tNon constructive ( 487 )\n",
      "Accuracy:  0.7561374795417348\n",
      "Precision-recall for each class:  (array([0.66735113, 0.81496599]), array([0.70498915, 0.78712221]), array([0.68565401, 0.80080214]), array([461, 761]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.70      0.67      0.69       487\n",
      "    constructive       0.79      0.81      0.80       735\n",
      "\n",
      "     avg / total       0.75      0.76      0.75      1222\n",
      "\n",
      "Results: \n",
      "macro_average => (0.7411585578790038, 0.7460556808172829, 0.7432280737381258, None)\n",
      "weighted_average => (0.7592782211806945, 0.7561374795417348, 0.7573624596544861, None)\n",
      "micro_average => (0.7561374795417348, 0.7561374795417348, 0.7561374795417348, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  315 \tConstructive ( 267 ) \tNon constructive ( 48 )\n",
      "Accuracy:  0.5746031746031746\n",
      "Precision-recall for each class:  (array([0.20833333, 0.64044944]), array([0.09433962, 0.81818182]), array([0.12987013, 0.71848739]), array([106, 209]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.09      0.21      0.13        48\n",
      "    constructive       0.82      0.64      0.72       267\n",
      "\n",
      "     avg / total       0.71      0.57      0.63       315\n",
      "\n",
      "Results: \n",
      "macro_average => (0.4243913857677903, 0.4562607204116638, 0.42417876241405655, None)\n",
      "weighted_average => (0.49503893942096194, 0.5746031746031746, 0.5204130136903247, None)\n",
      "micro_average => (0.5746031746031746, 0.5746031746031746, 0.5746031746031746, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  3\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10357\n",
      "Test samples:  2678\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4699 \tConstructive ( 2795 ) \tNon constructive ( 1904 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1220 \tConstructive ( 1029 ) \tNon constructive ( 191 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1244 \tConstructive ( 760 ) \tNon constructive ( 484 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  305 \tConstructive ( 263 ) \tNon constructive ( 42 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4699 \tConstructive ( 2795 ) \tNon constructive ( 1904 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2678 \tConstructive ( 1363 ) \tNon constructive ( 1315 )\n",
      "Accuracy:  0.876773711725168\n",
      "Precision-recall for each class:  (array([0.83878327, 0.91342627]), array([0.9033579 , 0.85449554]), array([0.86987382, 0.88297872]), array([1221, 1457]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.90      0.84      0.87      1315\n",
      "    constructive       0.85      0.91      0.88      1363\n",
      "\n",
      "     avg / total       0.88      0.88      0.88      2678\n",
      "\n",
      "Results: \n",
      "macro_average => (0.876104767776293, 0.8789267210681075, 0.8764262702194778, None)\n",
      "weighted_average => (0.8793937421915949, 0.876773711725168, 0.8770037082148503, None)\n",
      "micro_average => (0.876773711725168, 0.876773711725168, 0.876773711725168, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1244 \tConstructive ( 760 ) \tNon constructive ( 484 )\n",
      "Accuracy:  0.7676848874598071\n",
      "Precision-recall for each class:  (array([0.61157025, 0.86710526]), array([0.74559194, 0.77804014]), array([0.67196368, 0.82016179]), array([397, 847]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.75      0.61      0.67       484\n",
      "    constructive       0.78      0.87      0.82       760\n",
      "\n",
      "     avg / total       0.77      0.77      0.76      1244\n",
      "\n",
      "Results: \n",
      "macro_average => (0.7393377555458895, 0.7618160406115524, 0.7460627348991747, None)\n",
      "weighted_average => (0.7855559054055377, 0.7676848874598071, 0.7728670562553305, None)\n",
      "micro_average => (0.7676848874598071, 0.7676848874598071, 0.7676848874598071, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  305 \tConstructive ( 263 ) \tNon constructive ( 42 )\n",
      "Accuracy:  0.6163934426229508\n",
      "Precision-recall for each class:  (array([0.16666667, 0.68821293]), array([0.07865169, 0.83796296]), array([0.10687023, 0.75574113]), array([ 89, 216]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.08      0.17      0.11        42\n",
      "    constructive       0.84      0.69      0.76       263\n",
      "\n",
      "     avg / total       0.73      0.62      0.67       305\n",
      "\n",
      "Results: \n",
      "macro_average => (0.4274397972116603, 0.45830732417811065, 0.43130567817813825, None)\n",
      "weighted_average => (0.5360240187828544, 0.6163934426229508, 0.5663984717671681, None)\n",
      "micro_average => (0.6163934426229508, 0.6163934426229508, 0.6163934426229508, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  4\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10435\n",
      "Test samples:  2600\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4748 \tConstructive ( 2842 ) \tNon constructive ( 1906 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1210 \tConstructive ( 1018 ) \tNon constructive ( 192 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1195 \tConstructive ( 713 ) \tNon constructive ( 482 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  315 \tConstructive ( 274 ) \tNon constructive ( 41 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4748 \tConstructive ( 2842 ) \tNon constructive ( 1906 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2600 \tConstructive ( 1287 ) \tNon constructive ( 1313 )\n",
      "Accuracy:  0.8742307692307693\n",
      "Precision-recall for each class:  (array([0.86824067, 0.88034188]), array([0.88098918, 0.86753446]), array([0.87456847, 0.87389125]), array([1294, 1306]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.88      0.87      0.87      1313\n",
      "    constructive       0.87      0.88      0.87      1287\n",
      "\n",
      "     avg / total       0.87      0.87      0.87      2600\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8742912752813743, 0.8742618185949522, 0.8742298575832872, None)\n",
      "weighted_average => (0.8743192011508844, 0.8742307692307693, 0.8742282947590323, None)\n",
      "micro_average => (0.8742307692307693, 0.8742307692307693, 0.8742307692307693, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1195 \tConstructive ( 713 ) \tNon constructive ( 482 )\n",
      "Accuracy:  0.7589958158995815\n",
      "Precision-recall for each class:  (array([0.67842324, 0.81346424]), array([0.71086957, 0.78911565]), array([0.69426752, 0.80110497]), array([460, 735]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.71      0.68      0.69       482\n",
      "    constructive       0.79      0.81      0.80       713\n",
      "\n",
      "     avg / total       0.76      0.76      0.76      1195\n",
      "\n",
      "Results: \n",
      "macro_average => (0.7459437360693231, 0.7499926057379473, 0.7476862441496287, None)\n",
      "weighted_average => (0.7614819263434403, 0.7589958158995815, 0.7599792569213165, None)\n",
      "micro_average => (0.7589958158995815, 0.7589958158995815, 0.7589958158995815, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  315 \tConstructive ( 274 ) \tNon constructive ( 41 )\n",
      "Accuracy:  0.6126984126984127\n",
      "Precision-recall for each class:  (array([0.41463415, 0.64233577]), array([0.14782609, 0.88      ]), array([0.21794872, 0.74261603]), array([115, 200]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.15      0.41      0.22        41\n",
      "    constructive       0.88      0.64      0.74       274\n",
      "\n",
      "     avg / total       0.78      0.61      0.67       315\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5284849563824106, 0.5139130434782608, 0.4802823758519961, None)\n",
      "weighted_average => (0.5592066035363169, 0.6126984126984127, 0.5510708232227219, None)\n",
      "micro_average => (0.6126984126984127, 0.6126984126984127, 0.6126984126984127, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  5\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10402\n",
      "Test samples:  2633\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4748 \tConstructive ( 2842 ) \tNon constructive ( 1906 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1223 \tConstructive ( 1041 ) \tNon constructive ( 182 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1195 \tConstructive ( 713 ) \tNon constructive ( 482 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  302 \tConstructive ( 251 ) \tNon constructive ( 51 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4748 \tConstructive ( 2842 ) \tNon constructive ( 1906 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2633 \tConstructive ( 1276 ) \tNon constructive ( 1357 )\n",
      "Accuracy:  0.8754272692745917\n",
      "Precision-recall for each class:  (array([0.84377303, 0.90909091]), array([0.90800952, 0.84548105]), array([0.87471352, 0.87613293]), array([1261, 1372]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.84      0.87      1357\n",
      "    constructive       0.85      0.91      0.88      1276\n",
      "\n",
      "     avg / total       0.88      0.88      0.88      2633\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8764319689153882, 0.8767452829098106, 0.8754232261429702, None)\n",
      "weighted_average => (0.8778087795342575, 0.8754272692745917, 0.875453145316969, None)\n",
      "micro_average => (0.8754272692745917, 0.8754272692745917, 0.8754272692745917, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1195 \tConstructive ( 713 ) \tNon constructive ( 482 )\n",
      "Accuracy:  0.7665271966527196\n",
      "Precision-recall for each class:  (array([0.63692946, 0.85413745]), array([0.74695864, 0.77678571]), array([0.68756999, 0.81362725]), array([411, 784]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.75      0.64      0.69       482\n",
      "    constructive       0.78      0.85      0.81       713\n",
      "\n",
      "     avg / total       0.76      0.77      0.76      1195\n",
      "\n",
      "Results: \n",
      "macro_average => (0.7455334539931212, 0.7618721758776503, 0.7505986216554049, None)\n",
      "weighted_average => (0.7794324410581872, 0.7665271966527196, 0.7702719940858632, None)\n",
      "micro_average => (0.7665271966527196, 0.7665271966527196, 0.7665271966527196, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  302 \tConstructive ( 251 ) \tNon constructive ( 51 )\n",
      "Accuracy:  0.5794701986754967\n",
      "Precision-recall for each class:  (array([0.09803922, 0.67729084]), array([0.05813953, 0.78703704]), array([0.0729927 , 0.72805139]), array([ 86, 216]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.06      0.10      0.07        51\n",
      "    constructive       0.79      0.68      0.73       251\n",
      "\n",
      "     avg / total       0.66      0.58      0.62       302\n",
      "\n",
      "Results: \n",
      "macro_average => (0.38766502616983045, 0.422588285960379, 0.400522046296441, None)\n",
      "weighted_average => (0.5123383882985135, 0.5794701986754967, 0.541511499686, None)\n",
      "micro_average => (0.5794701986754967, 0.5794701986754967, 0.5794701986754967, None)\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "feature_set = perspective_feats\n",
    "avg_results_perspective_dict = run_n_experiments(all_SOCC_df, feature_set, train_balanced = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>test_balanced</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.750175</td>\n",
       "      <td>0.746019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.765315</td>\n",
       "      <td>0.765315</td>\n",
       "      <td>0.765315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.765315</td>\n",
       "      <td>0.768262</td>\n",
       "      <td>0.775259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_all</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.876875</td>\n",
       "      <td>0.875824</td>\n",
       "      <td>0.876102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.875900</td>\n",
       "      <td>0.875900</td>\n",
       "      <td>0.875900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.875900</td>\n",
       "      <td>0.875962</td>\n",
       "      <td>0.877348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_hard</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.468373</td>\n",
       "      <td>0.442304</td>\n",
       "      <td>0.450606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.606125</td>\n",
       "      <td>0.606125</td>\n",
       "      <td>0.606125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.606125</td>\n",
       "      <td>0.557218</td>\n",
       "      <td>0.537580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print_results(avg_results_perspective_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  1\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10468\n",
      "Test samples:  2567\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4761 \tConstructive ( 2843 ) \tNon constructive ( 1918 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1219 \tConstructive ( 1038 ) \tNon constructive ( 181 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1182 \tConstructive ( 712 ) \tNon constructive ( 470 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  306 \tConstructive ( 254 ) \tNon constructive ( 52 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats']\n",
      "Size of the training data:  4761 \tConstructive ( 2843 ) \tNon constructive ( 1918 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2567 \tConstructive ( 1304 ) \tNon constructive ( 1263 )\n",
      "Accuracy:  0.5079859758472925\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.        , 0.50798598]), array([0.        , 0.67372772]), array([   0, 2567]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00      1263\n",
      "    constructive       0.51      1.00      0.67      1304\n",
      "\n",
      "     avg / total       0.26      0.51      0.34      2567\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.2539929879236463, 0.3368638594678378, None)\n",
      "weighted_average => (1.0, 0.5079859758472925, 0.6737277189356756, None)\n",
      "micro_average => (0.5079859758472925, 0.5079859758472925, 0.5079859758472925, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1182 \tConstructive ( 712 ) \tNon constructive ( 470 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vkolhatk/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/vkolhatk/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6023688663282571\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.        , 0.60236887]), array([0.        , 0.75184794]), array([   0, 1182]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00       470\n",
      "    constructive       0.60      1.00      0.75       712\n",
      "\n",
      "     avg / total       0.36      0.60      0.45      1182\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.3011844331641286, 0.3759239704329461, None)\n",
      "weighted_average => (1.0, 0.6023688663282571, 0.7518479408658922, None)\n",
      "micro_average => (0.6023688663282571, 0.6023688663282571, 0.6023688663282571, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  306 \tConstructive ( 254 ) \tNon constructive ( 52 )\n",
      "Accuracy:  0.8300653594771242\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.        , 0.83006536]), array([0.        , 0.90714286]), array([  0, 306]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        52\n",
      "    constructive       0.83      1.00      0.91       254\n",
      "\n",
      "     avg / total       0.69      0.83      0.75       306\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.4150326797385621, 0.45357142857142857, None)\n",
      "weighted_average => (1.0, 0.8300653594771242, 0.9071428571428571, None)\n",
      "micro_average => (0.8300653594771242, 0.8300653594771242, 0.8300653594771242, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  2\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10456\n",
      "Test samples:  2579\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4768 \tConstructive ( 2831 ) \tNon constructive ( 1937 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1248 \tConstructive ( 1055 ) \tNon constructive ( 193 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1175 \tConstructive ( 724 ) \tNon constructive ( 451 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  277 \tConstructive ( 237 ) \tNon constructive ( 40 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats']\n",
      "Size of the training data:  4768 \tConstructive ( 2831 ) \tNon constructive ( 1937 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2579 \tConstructive ( 1271 ) \tNon constructive ( 1308 )\n",
      "Accuracy:  0.4928266770065917\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.        , 0.49282668]), array([0.        , 0.66025974]), array([   0, 2579]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00      1308\n",
      "    constructive       0.49      1.00      0.66      1271\n",
      "\n",
      "     avg / total       0.24      0.49      0.33      2579\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.24641333850329586, 0.33012987012987016, None)\n",
      "weighted_average => (1.0, 0.4928266770065917, 0.6602597402597403, None)\n",
      "micro_average => (0.4928266770065917, 0.4928266770065917, 0.4928266770065917, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1175 \tConstructive ( 724 ) \tNon constructive ( 451 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vkolhatk/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/vkolhatk/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6161702127659574\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.        , 0.61617021]), array([0.        , 0.76250658]), array([   0, 1175]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00       451\n",
      "    constructive       0.62      1.00      0.76       724\n",
      "\n",
      "     avg / total       0.38      0.62      0.47      1175\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.3080851063829787, 0.38125329120589785, None)\n",
      "weighted_average => (1.0, 0.6161702127659574, 0.7625065824117957, None)\n",
      "micro_average => (0.6161702127659574, 0.6161702127659574, 0.6161702127659574, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  277 \tConstructive ( 237 ) \tNon constructive ( 40 )\n",
      "Accuracy:  0.855595667870036\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.        , 0.85559567]), array([0.        , 0.92217899]), array([  0, 277]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        40\n",
      "    constructive       0.86      1.00      0.92       237\n",
      "\n",
      "     avg / total       0.73      0.86      0.79       277\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.427797833935018, 0.4610894941634241, None)\n",
      "weighted_average => (1.0, 0.855595667870036, 0.9221789883268482, None)\n",
      "micro_average => (0.855595667870036, 0.855595667870036, 0.855595667870036, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  3\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10428\n",
      "Test samples:  2607\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4792 \tConstructive ( 2889 ) \tNon constructive ( 1903 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1259 \tConstructive ( 1069 ) \tNon constructive ( 190 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1151 \tConstructive ( 666 ) \tNon constructive ( 485 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  266 \tConstructive ( 223 ) \tNon constructive ( 43 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats']\n",
      "Size of the training data:  4792 \tConstructive ( 2889 ) \tNon constructive ( 1903 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2607 \tConstructive ( 1237 ) \tNon constructive ( 1370 )\n",
      "Accuracy:  0.47449175297276563\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.        , 0.47449175]), array([0.        , 0.64360042]), array([   0, 2607]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00      1370\n",
      "    constructive       0.47      1.00      0.64      1237\n",
      "\n",
      "     avg / total       0.23      0.47      0.31      2607\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.23724587648638282, 0.32180020811654525, None)\n",
      "weighted_average => (1.0, 0.47449175297276563, 0.6436004162330905, None)\n",
      "micro_average => (0.47449175297276563, 0.47449175297276563, 0.4744917529727656, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1151 \tConstructive ( 666 ) \tNon constructive ( 485 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vkolhatk/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/vkolhatk/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.578627280625543\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.        , 0.57862728]), array([0.       , 0.7330765]), array([   0, 1151]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00       485\n",
      "    constructive       0.58      1.00      0.73       666\n",
      "\n",
      "     avg / total       0.33      0.58      0.42      1151\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.2893136403127715, 0.36653824986241057, None)\n",
      "weighted_average => (1.0, 0.578627280625543, 0.7330764997248211, None)\n",
      "micro_average => (0.578627280625543, 0.578627280625543, 0.578627280625543, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  266 \tConstructive ( 223 ) \tNon constructive ( 43 )\n",
      "Accuracy:  0.8383458646616542\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.        , 0.83834586]), array([0.        , 0.91206544]), array([  0, 266]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        43\n",
      "    constructive       0.84      1.00      0.91       223\n",
      "\n",
      "     avg / total       0.70      0.84      0.76       266\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.4191729323308271, 0.4560327198364008, None)\n",
      "weighted_average => (1.0, 0.8383458646616542, 0.9120654396728016, None)\n",
      "micro_average => (0.8383458646616542, 0.8383458646616542, 0.8383458646616542, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  4\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10376\n",
      "Test samples:  2659\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4771 \tConstructive ( 2858 ) \tNon constructive ( 1913 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1237 \tConstructive ( 1048 ) \tNon constructive ( 189 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1172 \tConstructive ( 697 ) \tNon constructive ( 475 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  288 \tConstructive ( 244 ) \tNon constructive ( 44 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats']\n",
      "Size of the training data:  4771 \tConstructive ( 2858 ) \tNon constructive ( 1913 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2659 \tConstructive ( 1295 ) \tNon constructive ( 1364 )\n",
      "Accuracy:  0.4870251974426476\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.       , 0.4870252]), array([0.        , 0.65503288]), array([   0, 2659]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00      1364\n",
      "    constructive       0.49      1.00      0.66      1295\n",
      "\n",
      "     avg / total       0.24      0.49      0.32      2659\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.2435125987213238, 0.32751643904906425, None)\n",
      "weighted_average => (1.0, 0.4870251974426476, 0.6550328780981285, None)\n",
      "micro_average => (0.4870251974426476, 0.4870251974426476, 0.4870251974426476, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1172 \tConstructive ( 697 ) \tNon constructive ( 475 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vkolhatk/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/vkolhatk/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5947098976109215\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.       , 0.5947099]), array([0.       , 0.7458534]), array([   0, 1172]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00       475\n",
      "    constructive       0.59      1.00      0.75       697\n",
      "\n",
      "     avg / total       0.35      0.59      0.44      1172\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.29735494880546076, 0.3729266987693954, None)\n",
      "weighted_average => (1.0, 0.5947098976109215, 0.7458533975387908, None)\n",
      "micro_average => (0.5947098976109215, 0.5947098976109215, 0.5947098976109215, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  288 \tConstructive ( 244 ) \tNon constructive ( 44 )\n",
      "Accuracy:  0.8472222222222222\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.        , 0.84722222]), array([0.        , 0.91729323]), array([  0, 288]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        44\n",
      "    constructive       0.85      1.00      0.92       244\n",
      "\n",
      "     avg / total       0.72      0.85      0.78       288\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.4236111111111111, 0.45864661654135336, None)\n",
      "weighted_average => (1.0, 0.8472222222222222, 0.9172932330827067, None)\n",
      "micro_average => (0.8472222222222222, 0.8472222222222222, 0.8472222222222222, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  5\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10481\n",
      "Test samples:  2554\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4815 \tConstructive ( 2881 ) \tNon constructive ( 1934 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1239 \tConstructive ( 1050 ) \tNon constructive ( 189 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1128 \tConstructive ( 674 ) \tNon constructive ( 454 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  286 \tConstructive ( 242 ) \tNon constructive ( 44 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats']\n",
      "Size of the training data:  4815 \tConstructive ( 2881 ) \tNon constructive ( 1934 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2554 \tConstructive ( 1265 ) \tNon constructive ( 1289 )\n",
      "Accuracy:  0.495301487862177\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.        , 0.49530149]), array([0.        , 0.66247709]), array([   0, 2554]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00      1289\n",
      "    constructive       0.50      1.00      0.66      1265\n",
      "\n",
      "     avg / total       0.25      0.50      0.33      2554\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.2476507439310885, 0.3312385441214978, None)\n",
      "weighted_average => (1.0, 0.495301487862177, 0.6624770882429956, None)\n",
      "micro_average => (0.495301487862177, 0.495301487862177, 0.495301487862177, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1128 \tConstructive ( 674 ) \tNon constructive ( 454 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vkolhatk/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/vkolhatk/.local/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5975177304964538\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.        , 0.59751773]), array([0.        , 0.74805771]), array([   0, 1128]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00       454\n",
      "    constructive       0.60      1.00      0.75       674\n",
      "\n",
      "     avg / total       0.36      0.60      0.45      1128\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.2987588652482269, 0.37402885682574916, None)\n",
      "weighted_average => (1.0, 0.5975177304964538, 0.7480577136514983, None)\n",
      "micro_average => (0.5975177304964538, 0.5975177304964538, 0.5975177304964538, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  286 \tConstructive ( 242 ) \tNon constructive ( 44 )\n",
      "Accuracy:  0.8461538461538461\n",
      "Precision-recall for each class:  (array([0., 1.]), array([0.        , 0.84615385]), array([0.        , 0.91666667]), array([  0, 286]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        44\n",
      "    constructive       0.85      1.00      0.92       242\n",
      "\n",
      "     avg / total       0.72      0.85      0.78       286\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.4230769230769231, 0.4583333333333333, None)\n",
      "weighted_average => (1.0, 0.8461538461538461, 0.9166666666666665, None)\n",
      "micro_average => (0.8461538461538461, 0.8461538461538461, 0.8461538461538461, None)\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "feature_set = text_feats\n",
    "avg_results_text_dict = run_n_experiments(all_SOCC_df, feature_set, train_balanced = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>test_balanced</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.298939</td>\n",
       "      <td>0.374134</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.597879</td>\n",
       "      <td>0.597879</td>\n",
       "      <td>0.597879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.597879</td>\n",
       "      <td>0.748268</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_all</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.245763</td>\n",
       "      <td>0.329510</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.491526</td>\n",
       "      <td>0.491526</td>\n",
       "      <td>0.491526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.491526</td>\n",
       "      <td>0.659020</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_hard</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.421738</td>\n",
       "      <td>0.457535</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.843477</td>\n",
       "      <td>0.843477</td>\n",
       "      <td>0.843477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.843477</td>\n",
       "      <td>0.915069</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print_results(avg_results_text_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only non length features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  1\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10436\n",
      "Test samples:  2599\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4805 \tConstructive ( 2876 ) \tNon constructive ( 1929 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1220 \tConstructive ( 1042 ) \tNon constructive ( 178 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1138 \tConstructive ( 679 ) \tNon constructive ( 459 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  305 \tConstructive ( 250 ) \tNon constructive ( 55 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4805 \tConstructive ( 2876 ) \tNon constructive ( 1929 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2599 \tConstructive ( 1274 ) \tNon constructive ( 1325 )\n",
      "Accuracy:  0.877645248172374\n",
      "Precision-recall for each class:  (array([0.84377358, 0.91287284]), array([0.90968267, 0.84890511]), array([0.87548943, 0.87972769]), array([1229, 1370]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.84      0.88      1325\n",
      "    constructive       0.85      0.91      0.88      1274\n",
      "\n",
      "     avg / total       0.88      0.88      0.88      2599\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8783232131749652, 0.8792938891627518, 0.8776085568364773, None)\n",
      "weighted_average => (0.8801975870056586, 0.877645248172374, 0.8777235230222868, None)\n",
      "micro_average => (0.877645248172374, 0.877645248172374, 0.877645248172374, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1138 \tConstructive ( 679 ) \tNon constructive ( 459 )\n",
      "Accuracy:  0.7592267135325131\n",
      "Precision-recall for each class:  (array([0.61873638, 0.85419735]), array([0.74151436, 0.76821192]), array([0.67458432, 0.80892608]), array([383, 755]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.74      0.62      0.67       459\n",
      "    constructive       0.77      0.85      0.81       679\n",
      "\n",
      "     avg / total       0.76      0.76      0.75      1138\n",
      "\n",
      "Results: \n",
      "macro_average => (0.7364668662424878, 0.7548631404215587, 0.7417552019664941, None)\n",
      "weighted_average => (0.7749516989328943, 0.7592267135325131, 0.7637126421778424, None)\n",
      "micro_average => (0.7592267135325131, 0.7592267135325131, 0.7592267135325131, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  305 \tConstructive ( 250 ) \tNon constructive ( 55 )\n",
      "Accuracy:  0.6098360655737705\n",
      "Precision-recall for each class:  (array([0.2, 0.7]), array([0.12790698, 0.79908676]), array([0.15602837, 0.74626866]), array([ 86, 219]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.13      0.20      0.16        55\n",
      "    constructive       0.80      0.70      0.75       250\n",
      "\n",
      "     avg / total       0.68      0.61      0.64       305\n",
      "\n",
      "Results: \n",
      "macro_average => (0.44999999999999996, 0.4634968673675268, 0.45114851275537204, None)\n",
      "weighted_average => (0.5590163934426229, 0.6098360655737705, 0.5798402476629757, None)\n",
      "micro_average => (0.6098360655737705, 0.6098360655737705, 0.6098360655737705, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  2\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10474\n",
      "Test samples:  2561\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4791 \tConstructive ( 2876 ) \tNon constructive ( 1915 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1247 \tConstructive ( 1053 ) \tNon constructive ( 194 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1152 \tConstructive ( 679 ) \tNon constructive ( 473 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  278 \tConstructive ( 239 ) \tNon constructive ( 39 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4791 \tConstructive ( 2876 ) \tNon constructive ( 1915 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2561 \tConstructive ( 1238 ) \tNon constructive ( 1323 )\n",
      "Accuracy:  0.8723155017571261\n",
      "Precision-recall for each class:  (array([0.82237339, 0.92568659]), array([0.9220339 , 0.82983345]), array([0.86935677, 0.87514318]), array([1180, 1381]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.92      0.82      0.87      1323\n",
      "    constructive       0.83      0.93      0.88      1238\n",
      "\n",
      "     avg / total       0.88      0.87      0.87      2561\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8740299925391086, 0.8759336761619558, 0.8722499781476432, None)\n",
      "weighted_average => (0.8780842589765026, 0.8723155017571261, 0.8724770513460237, None)\n",
      "micro_average => (0.8723155017571261, 0.8723155017571261, 0.8723155017571261, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1152 \tConstructive ( 679 ) \tNon constructive ( 473 )\n",
      "Accuracy:  0.7543402777777778\n",
      "Precision-recall for each class:  (array([0.56659619, 0.88512518]), array([0.77456647, 0.74565757]), array([0.65445665, 0.80942761]), array([346, 806]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.77      0.57      0.65       473\n",
      "    constructive       0.75      0.89      0.81       679\n",
      "\n",
      "     avg / total       0.76      0.75      0.75      1152\n",
      "\n",
      "Results: \n",
      "macro_average => (0.7258606892987137, 0.7601120211133263, 0.731942131942132, None)\n",
      "weighted_average => (0.7894558868733227, 0.7543402777777778, 0.7628825135769579, None)\n",
      "micro_average => (0.7543402777777778, 0.7543402777777778, 0.7543402777777778, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  278 \tConstructive ( 239 ) \tNon constructive ( 39 )\n",
      "Accuracy:  0.6258992805755396\n",
      "Precision-recall for each class:  (array([0.07692308, 0.71548117]), array([0.04225352, 0.82608696]), array([0.05454545, 0.76681614]), array([ 71, 207]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.04      0.08      0.05        39\n",
      "    constructive       0.83      0.72      0.77       239\n",
      "\n",
      "     avg / total       0.72      0.63      0.67       278\n",
      "\n",
      "Results: \n",
      "macro_average => (0.3962021242355971, 0.4341702388242499, 0.4106807990216062, None)\n",
      "weighted_average => (0.552396190546758, 0.6258992805755396, 0.584905284089076, None)\n",
      "micro_average => (0.6258992805755396, 0.6258992805755396, 0.6258992805755396, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  3\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10488\n",
      "Test samples:  2547\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4780 \tConstructive ( 2878 ) \tNon constructive ( 1902 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1249 \tConstructive ( 1061 ) \tNon constructive ( 188 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1163 \tConstructive ( 677 ) \tNon constructive ( 486 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  276 \tConstructive ( 231 ) \tNon constructive ( 45 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4780 \tConstructive ( 2878 ) \tNon constructive ( 1902 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2547 \tConstructive ( 1257 ) \tNon constructive ( 1290 )\n",
      "Accuracy:  0.8708284255987436\n",
      "Precision-recall for each class:  (array([0.82790698, 0.91487669]), array([0.90893617, 0.83819242]), array([0.86653144, 0.87485736]), array([1175, 1372]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.83      0.87      1290\n",
      "    constructive       0.84      0.91      0.87      1257\n",
      "\n",
      "     avg / total       0.87      0.87      0.87      2547\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8713918336386006, 0.8735642950189194, 0.8706944001876402, None)\n",
      "weighted_average => (0.8747552089068377, 0.8708284255987436, 0.8710163880655349, None)\n",
      "micro_average => (0.8708284255987436, 0.8708284255987436, 0.8708284255987436, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1163 \tConstructive ( 677 ) \tNon constructive ( 486 )\n",
      "Accuracy:  0.7549441100601891\n",
      "Precision-recall for each class:  (array([0.60493827, 0.86262925]), array([0.75968992, 0.75257732]), array([0.67353952, 0.80385409]), array([387, 776]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.76      0.60      0.67       486\n",
      "    constructive       0.75      0.86      0.80       677\n",
      "\n",
      "     avg / total       0.76      0.75      0.75      1163\n",
      "\n",
      "Results: \n",
      "macro_average => (0.7337837591407261, 0.7561336210341245, 0.7386968069381278, None)\n",
      "weighted_average => (0.7768799712227739, 0.7549441100601891, 0.7604906031949619, None)\n",
      "micro_average => (0.7549441100601891, 0.7549441100601891, 0.754944110060189, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  276 \tConstructive ( 231 ) \tNon constructive ( 45 )\n",
      "Accuracy:  0.5797101449275363\n",
      "Precision-recall for each class:  (array([0.11111111, 0.67099567]), array([0.0617284 , 0.79487179]), array([0.07936508, 0.72769953]), array([ 81, 195]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.06      0.11      0.08        45\n",
      "    constructive       0.79      0.67      0.73       231\n",
      "\n",
      "     avg / total       0.68      0.58      0.62       276\n",
      "\n",
      "Results: \n",
      "macro_average => (0.3910533910533911, 0.4283000949667616, 0.40353230494075565, None)\n",
      "weighted_average => (0.5066817240730285, 0.5797101449275363, 0.5374274633307088, None)\n",
      "micro_average => (0.5797101449275363, 0.5797101449275363, 0.5797101449275363, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  4\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10448\n",
      "Test samples:  2587\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4796 \tConstructive ( 2879 ) \tNon constructive ( 1917 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1250 \tConstructive ( 1066 ) \tNon constructive ( 184 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1147 \tConstructive ( 676 ) \tNon constructive ( 471 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  275 \tConstructive ( 226 ) \tNon constructive ( 49 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4796 \tConstructive ( 2879 ) \tNon constructive ( 1917 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2587 \tConstructive ( 1268 ) \tNon constructive ( 1319 )\n",
      "Accuracy:  0.8770776961731735\n",
      "Precision-recall for each class:  (array([0.82941622, 0.92665615]), array([0.92165122, 0.83928571]), array([0.87310455, 0.8808096 ]), array([1187, 1400]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.92      0.83      0.87      1319\n",
      "    constructive       0.84      0.93      0.88      1268\n",
      "\n",
      "     avg / total       0.88      0.88      0.88      2587\n",
      "\n",
      "Results: \n",
      "macro_average => (0.878036187915996, 0.8804684679263449, 0.8769570721423008, None)\n",
      "weighted_average => (0.8820393004889604, 0.8770776961731735, 0.8772742686679293, None)\n",
      "micro_average => (0.8770776961731735, 0.8770776961731735, 0.8770776961731735, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1147 \tConstructive ( 676 ) \tNon constructive ( 471 )\n",
      "Accuracy:  0.7654751525719268\n",
      "Precision-recall for each class:  (array([0.59447983, 0.88461538]), array([0.78212291, 0.75792142]), array([0.67551267, 0.81638225]), array([358, 789]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.78      0.59      0.68       471\n",
      "    constructive       0.76      0.88      0.82       676\n",
      "\n",
      "     avg / total       0.77      0.77      0.76      1147\n",
      "\n",
      "Results: \n",
      "macro_average => (0.7395476073820022, 0.7700221622731553, 0.745947459211106, None)\n",
      "weighted_average => (0.7940586901959411, 0.7654751525719268, 0.7724142385775015, None)\n",
      "micro_average => (0.7654751525719268, 0.7654751525719268, 0.7654751525719268, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  275 \tConstructive ( 226 ) \tNon constructive ( 49 )\n",
      "Accuracy:  0.6436363636363637\n",
      "Precision-recall for each class:  (array([0.18367347, 0.74336283]), array([0.13432836, 0.80769231]), array([0.15517241, 0.77419355]), array([ 67, 208]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.13      0.18      0.16        49\n",
      "    constructive       0.81      0.74      0.77       226\n",
      "\n",
      "     avg / total       0.69      0.64      0.66       275\n",
      "\n",
      "Results: \n",
      "macro_average => (0.4635181506230811, 0.47101033295063144, 0.46468298109010014, None)\n",
      "weighted_average => (0.6070021508201028, 0.6436363636363637, 0.6233774901405603, None)\n",
      "micro_average => (0.6436363636363637, 0.6436363636363637, 0.6436363636363637, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  5\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10412\n",
      "Test samples:  2623\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4719 \tConstructive ( 2814 ) \tNon constructive ( 1905 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1207 \tConstructive ( 1020 ) \tNon constructive ( 187 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1224 \tConstructive ( 741 ) \tNon constructive ( 483 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  318 \tConstructive ( 272 ) \tNon constructive ( 46 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4719 \tConstructive ( 2814 ) \tNon constructive ( 1905 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2623 \tConstructive ( 1296 ) \tNon constructive ( 1327 )\n",
      "Accuracy:  0.8772398017537171\n",
      "Precision-recall for each class:  (array([0.83647325, 0.91898148]), array([0.91358025, 0.84588068]), array([0.87332809, 0.88091716]), array([1215, 1408]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.84      0.87      1327\n",
      "    constructive       0.85      0.92      0.88      1296\n",
      "\n",
      "     avg / total       0.88      0.88      0.88      2623\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8777273647045689, 0.879730464365881, 0.8771226239414522, None)\n",
      "weighted_average => (0.8807628372695495, 0.8772398017537171, 0.8774018253953673, None)\n",
      "micro_average => (0.8772398017537171, 0.8772398017537171, 0.877239801753717, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1224 \tConstructive ( 741 ) \tNon constructive ( 483 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7720588235294118\n",
      "Precision-recall for each class:  (array([0.61904762, 0.87179487]), array([0.75888325, 0.77831325]), array([0.68187001, 0.82240611]), array([394, 830]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.76      0.62      0.68       483\n",
      "    constructive       0.78      0.87      0.82       741\n",
      "\n",
      "     avg / total       0.77      0.77      0.77      1224\n",
      "\n",
      "Results: \n",
      "macro_average => (0.7454212454212454, 0.7685982508715063, 0.7521380610799939, None)\n",
      "weighted_average => (0.7904366874955111, 0.7720588235294118, 0.7771681833507321, None)\n",
      "micro_average => (0.7720588235294118, 0.7720588235294118, 0.7720588235294118, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  318 \tConstructive ( 272 ) \tNon constructive ( 46 )\n",
      "Accuracy:  0.6383647798742138\n",
      "Precision-recall for each class:  (array([0.19565217, 0.71323529]), array([0.10344828, 0.83982684]), array([0.13533835, 0.77137177]), array([ 87, 231]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.10      0.20      0.14        46\n",
      "    constructive       0.84      0.71      0.77       272\n",
      "\n",
      "     avg / total       0.73      0.64      0.68       318\n",
      "\n",
      "Results: \n",
      "macro_average => (0.45444373401534527, 0.4716375578444544, 0.45335505762417977, None)\n",
      "weighted_average => (0.5716323650050668, 0.6383647798742138, 0.5973626252133956, None)\n",
      "micro_average => (0.6383647798742138, 0.6383647798742138, 0.6383647798742138, None)\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "feature_set = text_feats + perspective_feats\n",
    "avg_results_non_len_dict = run_n_experiments(all_SOCC_df, feature_set, train_balanced = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>test_balanced</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.761946</td>\n",
       "      <td>0.742096</td>\n",
       "      <td>0.736216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.761209</td>\n",
       "      <td>0.761209</td>\n",
       "      <td>0.761209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.761209</td>\n",
       "      <td>0.767334</td>\n",
       "      <td>0.785157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_all</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.877798</td>\n",
       "      <td>0.874927</td>\n",
       "      <td>0.875902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.875021</td>\n",
       "      <td>0.875021</td>\n",
       "      <td>0.875021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.875021</td>\n",
       "      <td>0.875179</td>\n",
       "      <td>0.879168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_hard</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.453723</td>\n",
       "      <td>0.436680</td>\n",
       "      <td>0.431043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.619489</td>\n",
       "      <td>0.619489</td>\n",
       "      <td>0.619489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.619489</td>\n",
       "      <td>0.584583</td>\n",
       "      <td>0.559346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print_results(avg_results_non_len_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  1\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10448\n",
      "Test samples:  2587\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4752 \tConstructive ( 2845 ) \tNon constructive ( 1907 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1250 \tConstructive ( 1055 ) \tNon constructive ( 195 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1191 \tConstructive ( 710 ) \tNon constructive ( 481 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  275 \tConstructive ( 237 ) \tNon constructive ( 38 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4752 \tConstructive ( 2845 ) \tNon constructive ( 1907 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2587 \tConstructive ( 1294 ) \tNon constructive ( 1293 )\n",
      "Accuracy:  0.9137997680711248\n",
      "Precision-recall for each class:  (array([0.90796597, 0.91962906]), array([0.91862285, 0.90909091]), array([0.91326332, 0.91432962]), array([1278, 1309]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.92      0.91      0.91      1293\n",
      "    constructive       0.91      0.92      0.91      1294\n",
      "\n",
      "     avg / total       0.91      0.91      0.91      2587\n",
      "\n",
      "Results: \n",
      "macro_average => (0.9137975138989995, 0.913856878645611, 0.9137964706671668, None)\n",
      "weighted_average => (0.9138673932348824, 0.9137997680711248, 0.9138028593873354, None)\n",
      "micro_average => (0.9137997680711248, 0.9137997680711248, 0.9137997680711248, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1191 \tConstructive ( 710 ) \tNon constructive ( 481 )\n",
      "Accuracy:  0.8421494542401343\n",
      "Precision-recall for each class:  (array([0.8004158 , 0.87042254]), array([0.80712788, 0.86554622]), array([0.80375783, 0.86797753]), array([477, 714]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.81      0.80      0.80       481\n",
      "    constructive       0.87      0.87      0.87       710\n",
      "\n",
      "     avg / total       0.84      0.84      0.84      1191\n",
      "\n",
      "Results: \n",
      "macro_average => (0.835419167813534, 0.8363370505434878, 0.8358676784499542, None)\n",
      "weighted_average => (0.8423845734166093, 0.8421494542401343, 0.842257295884601, None)\n",
      "micro_average => (0.8421494542401343, 0.8421494542401343, 0.8421494542401343, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  275 \tConstructive ( 237 ) \tNon constructive ( 38 )\n",
      "Accuracy:  0.5236363636363637\n",
      "Precision-recall for each class:  (array([0.07894737, 0.59493671]), array([0.03030303, 0.80113636]), array([0.04379562, 0.68280872]), array([ 99, 176]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.03      0.08      0.04        38\n",
      "    constructive       0.80      0.59      0.68       237\n",
      "\n",
      "     avg / total       0.69      0.52      0.59       275\n",
      "\n",
      "Results: \n",
      "macro_average => (0.33694203864090605, 0.41571969696969696, 0.363302168572489, None)\n",
      "weighted_average => (0.409180546302465, 0.5236363636363637, 0.4527640020501582, None)\n",
      "micro_average => (0.5236363636363637, 0.5236363636363637, 0.5236363636363637, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  2\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10419\n",
      "Test samples:  2616\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4758 \tConstructive ( 2853 ) \tNon constructive ( 1905 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1216 \tConstructive ( 1036 ) \tNon constructive ( 180 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1185 \tConstructive ( 702 ) \tNon constructive ( 483 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  309 \tConstructive ( 256 ) \tNon constructive ( 53 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4758 \tConstructive ( 2853 ) \tNon constructive ( 1905 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2616 \tConstructive ( 1288 ) \tNon constructive ( 1328 )\n",
      "Accuracy:  0.9139908256880734\n",
      "Precision-recall for each class:  (array([0.91340361, 0.91459627]), array([0.91685563, 0.91105955]), array([0.91512637, 0.91282449]), array([1323, 1293]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.92      0.91      0.92      1328\n",
      "    constructive       0.91      0.91      0.91      1288\n",
      "\n",
      "     avg / total       0.91      0.91      0.91      2616\n",
      "\n",
      "Results: \n",
      "macro_average => (0.9139999438748785, 0.9139575912860632, 0.9139754270208065, None)\n",
      "weighted_average => (0.9139931052347747, 0.9139908256880734, 0.9139886258784637, None)\n",
      "micro_average => (0.9139908256880734, 0.9139908256880734, 0.9139908256880735, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1185 \tConstructive ( 702 ) \tNon constructive ( 483 )\n",
      "Accuracy:  0.8481012658227848\n",
      "Precision-recall for each class:  (array([0.82194617, 0.86609687]), array([0.80855397, 0.87608069]), array([0.81519507, 0.87106017]), array([491, 694]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.81      0.82      0.82       483\n",
      "    constructive       0.88      0.87      0.87       702\n",
      "\n",
      "     avg / total       0.85      0.85      0.85      1185\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8440215179345614, 0.8423173315647066, 0.843127621894177, None)\n",
      "weighted_average => (0.8478032020501293, 0.8481012658227848, 0.847912691645397, None)\n",
      "micro_average => (0.8481012658227848, 0.8481012658227848, 0.8481012658227848, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  309 \tConstructive ( 256 ) \tNon constructive ( 53 )\n",
      "Accuracy:  0.4854368932038835\n",
      "Precision-recall for each class:  (array([0.03773585, 0.578125  ]), array([0.01818182, 0.74371859]), array([0.02453988, 0.65054945]), array([110, 199]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.02      0.04      0.02        53\n",
      "    constructive       0.74      0.58      0.65       256\n",
      "\n",
      "     avg / total       0.62      0.49      0.54       309\n",
      "\n",
      "Results: \n",
      "macro_average => (0.3079304245283019, 0.38095020557332115, 0.337544663925032, None)\n",
      "weighted_average => (0.38575345759296575, 0.4854368932038835, 0.42769814615666063, None)\n",
      "micro_average => (0.4854368932038835, 0.4854368932038835, 0.4854368932038835, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  3\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10463\n",
      "Test samples:  2572\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4756 \tConstructive ( 2831 ) \tNon constructive ( 1925 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1196 \tConstructive ( 1008 ) \tNon constructive ( 188 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1187 \tConstructive ( 724 ) \tNon constructive ( 463 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  329 \tConstructive ( 284 ) \tNon constructive ( 45 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4756 \tConstructive ( 2831 ) \tNon constructive ( 1925 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2572 \tConstructive ( 1284 ) \tNon constructive ( 1288 )\n",
      "Accuracy:  0.9082426127527217\n",
      "Precision-recall for each class:  (array([0.9076087, 0.9088785]), array([0.90902022, 0.90746501]), array([0.90831391, 0.90817121]), array([1286, 1286]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.91      0.91      1288\n",
      "    constructive       0.91      0.91      0.91      1284\n",
      "\n",
      "     avg / total       0.91      0.91      0.91      2572\n",
      "\n",
      "Results: \n",
      "macro_average => (0.9082436001625356, 0.9082426127527217, 0.9082425572697945, None)\n",
      "weighted_average => (0.9082436001625357, 0.9082426127527217, 0.9082425572697945, None)\n",
      "micro_average => (0.9082426127527217, 0.9082426127527217, 0.9082426127527217, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1187 \tConstructive ( 724 ) \tNon constructive ( 463 )\n",
      "Accuracy:  0.8323504633529908\n",
      "Precision-recall for each class:  (array([0.78185745, 0.86464088]), array([0.78695652, 0.8610729 ]), array([0.7843987, 0.8628532]), array([460, 727]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.79      0.78      0.78       463\n",
      "    constructive       0.86      0.86      0.86       724\n",
      "\n",
      "     avg / total       0.83      0.83      0.83      1187\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8232491676908942, 0.8240147120387536, 0.8236259522890406, None)\n",
      "weighted_average => (0.8325596885406251, 0.8323504633529908, 0.8324496055241721, None)\n",
      "micro_average => (0.8323504633529908, 0.8323504633529908, 0.8323504633529908, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  329 \tConstructive ( 284 ) \tNon constructive ( 45 )\n",
      "Accuracy:  0.5106382978723404\n",
      "Precision-recall for each class:  (array([0.02222222, 0.58802817]), array([0.00847458, 0.79146919]), array([0.01226994, 0.67474747]), array([118, 211]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.01      0.02      0.01        45\n",
      "    constructive       0.79      0.59      0.67       284\n",
      "\n",
      "     avg / total       0.68      0.51      0.58       329\n",
      "\n",
      "Results: \n",
      "macro_average => (0.3051251956181534, 0.3999718852919913, 0.3435087066988907, None)\n",
      "weighted_average => (0.3850947291312889, 0.5106382978723404, 0.43714154994666676, None)\n",
      "micro_average => (0.5106382978723404, 0.5106382978723404, 0.5106382978723404, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  4\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10461\n",
      "Test samples:  2574\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4745 \tConstructive ( 2837 ) \tNon constructive ( 1908 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1215 \tConstructive ( 1029 ) \tNon constructive ( 186 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1198 \tConstructive ( 718 ) \tNon constructive ( 480 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  310 \tConstructive ( 263 ) \tNon constructive ( 47 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4745 \tConstructive ( 2837 ) \tNon constructive ( 1908 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2574 \tConstructive ( 1285 ) \tNon constructive ( 1289 )\n",
      "Accuracy:  0.9133644133644133\n",
      "Precision-recall for each class:  (array([0.91621412, 0.91050584]), array([0.91126543, 0.91549296]), array([0.91373308, 0.91299259]), array([1296, 1278]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.92      0.91      1289\n",
      "    constructive       0.92      0.91      0.91      1285\n",
      "\n",
      "     avg / total       0.91      0.91      0.91      2574\n",
      "\n",
      "Results: \n",
      "macro_average => (0.9133599780241674, 0.9133791949226222, 0.9133628311237663, None)\n",
      "weighted_average => (0.9133799370552743, 0.9133644133644133, 0.9133654202448253, None)\n",
      "micro_average => (0.9133644133644133, 0.9133644133644133, 0.9133644133644133, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1198 \tConstructive ( 718 ) \tNon constructive ( 480 )\n",
      "Accuracy:  0.83889816360601\n",
      "Precision-recall for each class:  (array([0.80625   , 0.86072423]), array([0.79466119, 0.86919831]), array([0.80041365, 0.86494052]), array([487, 711]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.79      0.81      0.80       480\n",
      "    constructive       0.87      0.86      0.86       718\n",
      "\n",
      "     avg / total       0.84      0.84      0.84      1198\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8334871169916435, 0.8319297516006896, 0.8326770841550017, None)\n",
      "weighted_average => (0.8385798667463413, 0.83889816360601, 0.8387096460468887, None)\n",
      "micro_average => (0.83889816360601, 0.83889816360601, 0.83889816360601, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  310 \tConstructive ( 263 ) \tNon constructive ( 47 )\n",
      "Accuracy:  0.4870967741935484\n",
      "Precision-recall for each class:  (array([0.04255319, 0.56653992]), array([0.01724138, 0.76804124]), array([0.02453988, 0.65207877]), array([116, 194]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.02      0.04      0.02        47\n",
      "    constructive       0.77      0.57      0.65       263\n",
      "\n",
      "     avg / total       0.65      0.49      0.56       310\n",
      "\n",
      "Results: \n",
      "macro_average => (0.3045465577218671, 0.3926413082118735, 0.33830932595884067, None)\n",
      "weighted_average => (0.3704674692255298, 0.4870967741935484, 0.41725776787929786, None)\n",
      "micro_average => (0.4870967741935484, 0.4870967741935484, 0.4870967741935484, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  5\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10443\n",
      "Test samples:  2592\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4762 \tConstructive ( 2873 ) \tNon constructive ( 1889 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1231 \tConstructive ( 1048 ) \tNon constructive ( 183 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1181 \tConstructive ( 682 ) \tNon constructive ( 499 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  294 \tConstructive ( 244 ) \tNon constructive ( 50 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  4762 \tConstructive ( 2873 ) \tNon constructive ( 1889 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2592 \tConstructive ( 1288 ) \tNon constructive ( 1304 )\n",
      "Accuracy:  0.8668981481481481\n",
      "Precision-recall for each class:  (array([0.80521472, 0.92934783]), array([0.9202454 , 0.82494831]), array([0.85889571, 0.87404162]), array([1141, 1451]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.92      0.81      0.86      1304\n",
      "    constructive       0.82      0.93      0.87      1288\n",
      "\n",
      "     avg / total       0.87      0.87      0.87      2592\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8672812750066685, 0.872596855141155, 0.8664686632755225, None)\n",
      "weighted_average => (0.8747043578904993, 0.8668981481481481, 0.8673743796735763, None)\n",
      "micro_average => (0.8668981481481481, 0.8668981481481481, 0.8668981481481481, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1181 \tConstructive ( 682 ) \tNon constructive ( 499 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8602878916172735\n",
      "Precision-recall for each class:  (array([0.82164329, 0.88856305]), array([0.8436214 , 0.87194245]), array([0.83248731, 0.88017429]), array([486, 695]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.84      0.82      0.83       499\n",
      "    constructive       0.87      0.89      0.88       682\n",
      "\n",
      "     avg / total       0.86      0.86      0.86      1181\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8551031682132594, 0.8577819226100601, 0.856330800791834, None)\n",
      "weighted_average => (0.8610245189861498, 0.8602878916172735, 0.8605503517230424, None)\n",
      "micro_average => (0.8602878916172735, 0.8602878916172735, 0.8602878916172735, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  294 \tConstructive ( 244 ) \tNon constructive ( 50 )\n",
      "Accuracy:  0.5238095238095238\n",
      "Precision-recall for each class:  (array([0.02      , 0.62704918]), array([0.01086957, 0.75742574]), array([0.01408451, 0.68609865]), array([ 92, 202]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.01      0.02      0.01        50\n",
      "    constructive       0.76      0.63      0.69       244\n",
      "\n",
      "     avg / total       0.63      0.52      0.57       294\n",
      "\n",
      "Results: \n",
      "macro_average => (0.3235245901639344, 0.3841476538958244, 0.35009158087538683, None)\n",
      "weighted_average => (0.437088212334114, 0.5238095238095238, 0.4758085132619333, None)\n",
      "micro_average => (0.5238095238095238, 0.5238095238095238, 0.5238095238095238, None)\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "feature_set = all_feats\n",
    "avg_results_all_dict = run_n_experiments(all_SOCC_df, feature_set, train_balanced = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>test_balanced</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.838476</td>\n",
       "      <td>0.838326</td>\n",
       "      <td>0.838256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.844357</td>\n",
       "      <td>0.844357</td>\n",
       "      <td>0.844357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.844357</td>\n",
       "      <td>0.844376</td>\n",
       "      <td>0.844470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_all</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.904407</td>\n",
       "      <td>0.903169</td>\n",
       "      <td>0.903336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.903259</td>\n",
       "      <td>0.903259</td>\n",
       "      <td>0.903259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.903259</td>\n",
       "      <td>0.903355</td>\n",
       "      <td>0.904838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_hard</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.394686</td>\n",
       "      <td>0.346551</td>\n",
       "      <td>0.315614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.506124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.506124</td>\n",
       "      <td>0.442134</td>\n",
       "      <td>0.397517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print_results(avg_results_all_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
