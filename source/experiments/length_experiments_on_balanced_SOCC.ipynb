{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from config import Config\n",
    "from experiments_utils import *\n",
    "import pickle as pkl\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_feats = ['ngram_feats', 'tfidf_feats']\n",
    "\n",
    "pos_feats =  ['pos_feats']\n",
    "\n",
    "len_feats = ['length_feats']\n",
    "\n",
    "argumentation_feats = ['argumentation_feats']\n",
    "\n",
    "named_entity_feats = ['named_entity_feats']\n",
    "\n",
    "text_quality_feats = ['text_quality_feats']\n",
    "\n",
    "content_value_feats = ['perspective_content_value_feats']\n",
    "\n",
    "aggressiveness_feats = ['perspective_aggressiveness_feats']\n",
    "\n",
    "toxicity_feats = ['perspecitive_toxicity_feats']\n",
    "\n",
    "crowd_annotated_feats = ['constructiveness_chars_feats',\n",
    "                         'non_constructiveness_chars_feats',\n",
    "                         'toxicity_chars_feats']\n",
    "\n",
    "perspective_feats = ['perspective_content_value_feats',\n",
    "                     'perspective_aggressiveness_feats',\n",
    "                     'perspecitive_toxicity_feats']\n",
    "\n",
    "all_feats = (lexical_feats + pos_feats + len_feats + \n",
    "            argumentation_feats + named_entity_feats + \n",
    "            text_quality_feats + content_value_feats + \n",
    "            aggressiveness_feats + toxicity_feats)\n",
    "            \n",
    "\n",
    "#no_len_feats = lexical_feats + discourse_feats + text_quality_feats + named_entity_feats + perspective_feats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_upper_ranges = [[10,20], [20, 30], [30, 40], [40, 50], [50, 60], [60, 70], [70, 80]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_balanced_df(df):\n",
    "    balanced_dfs = []\n",
    "    for (lower, upper) in lower_upper_ranges:\n",
    "        print('LOWER: ', lower)\n",
    "        print('UPPER: ', upper)    \n",
    "        subset_df = df[(df['comment_len'] >= lower) & (df['comment_len'] < upper)]\n",
    "        d = subset_df['constructive'].value_counts().to_dict()\n",
    "        lower_count = min(list(d.values()))\n",
    "        con_subset_df = subset_df[subset_df['constructive'] == 1.0].sample(n=lower_count)\n",
    "        print('Number of constructive samples: ', con_subset_df.shape[0])\n",
    "        non_con_subset_df = subset_df[subset_df['constructive'] == 0.0].sample(n=lower_count)\n",
    "        print('Number of non-constructive samples: ', non_con_subset_df.shape[0])\n",
    "        balanced_dfs.extend([con_subset_df, non_con_subset_df])\n",
    "        \n",
    "    result_df = pd.concat(balanced_dfs)    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_balanced_data(train_df, balanced_df, feat_sets):\n",
    "    for feat_set in feat_sets:\n",
    "        print('FEATURE SET: ', feat_set)\n",
    "        model_path = Config.MODEL_PATH + 'tmp.pkl'\n",
    "        print('TRAINING ON ', train_df.shape)\n",
    "        train_and_save_model(train_df, model_path, feat_set)    \n",
    "        predicted, targets = get_predictions_with_model(model_path, balanced_df)\n",
    "        print('Performance on the balanced test set: ')\n",
    "        get_eval_results(predicted, targets)\n",
    "\n",
    "        print('\\n\\n**************************\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_sets = [lexical_feats,\n",
    "             pos_feats,\n",
    "             len_feats,\n",
    "             argumentation_feats,\n",
    "             named_entity_feats,\n",
    "             text_quality_feats,\n",
    "             content_value_feats, \n",
    "             aggressiveness_feats,\n",
    "             toxicity_feats,\n",
    "             #crowd_annotated_feats,\n",
    "             all_feats\n",
    "            ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train: Subset of CTC + SOCC*  Test: Balanced dataset of CTC + SOCC* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_SOCC_df = pd.read_csv(Config.ALL_SOCC_FEATURES_FILE_PATH)\n",
    "all_SOCC_df['comment_len'] = all_SOCC_df['pp_comment_text'].apply(lambda x: len(x.split()))\n",
    "SOCC_df = all_SOCC_df[all_SOCC_df['source'] == 'SOCC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOWER:  10\n",
      "UPPER:  20\n",
      "Number of constructive samples:  17\n",
      "Number of non-constructive samples:  17\n",
      "LOWER:  20\n",
      "UPPER:  30\n",
      "Number of constructive samples:  65\n",
      "Number of non-constructive samples:  65\n",
      "LOWER:  30\n",
      "UPPER:  40\n",
      "Number of constructive samples:  111\n",
      "Number of non-constructive samples:  111\n",
      "LOWER:  40\n",
      "UPPER:  50\n",
      "Number of constructive samples:  307\n",
      "Number of non-constructive samples:  307\n",
      "LOWER:  50\n",
      "UPPER:  60\n",
      "Number of constructive samples:  62\n",
      "Number of non-constructive samples:  62\n",
      "LOWER:  60\n",
      "UPPER:  70\n",
      "Number of constructive samples:  18\n",
      "Number of non-constructive samples:  18\n",
      "LOWER:  70\n",
      "UPPER:  80\n",
      "Number of constructive samples:  7\n",
      "Number of non-constructive samples:  7\n"
     ]
    }
   ],
   "source": [
    "balanced_df = get_balanced_df(all_SOCC_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1174, 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = all_SOCC_df[~all_SOCC_df['comment_counter'].isin(balanced_df['comment_counter'].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10623, 37)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.to_csv(Config.TRAIN_PATH + 'CTC_len_balanced_test.csv', index = False)\n",
    "train_df.to_csv(Config.TRAIN_PATH + 'CTC-CTC_len_balanced_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE SET:  ['ngram_feats', 'tfidf_feats']\n",
      "TRAINING ON  (10623, 37)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['ngram_feats', 'tfidf_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  10623 \tConstructive ( 5870 ) \tNon constructive ( 4753 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.5383304940374787\n",
      "Precision-recall for each class:  (array([0.77172061, 0.30494037]), array([0.5261324 , 0.57188498]), array([0.62569061, 0.39777778]), array([861, 313]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.53      0.77      0.63       587\n",
      "    constructive       0.57      0.30      0.40       587\n",
      "\n",
      "     avg / total       0.55      0.54      0.51      1174\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5383304940374787, 0.5490086941033718, 0.5117341927562922, None)\n",
      "weighted_average => (0.6472723895649348, 0.5383304940374787, 0.5649267953186652, None)\n",
      "micro_average => (0.5383304940374787, 0.5383304940374787, 0.5383304940374787, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['pos_feats']\n",
      "TRAINING ON  (10623, 37)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['pos_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  10623 \tConstructive ( 5870 ) \tNon constructive ( 4753 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.555366269165247\n",
      "Precision-recall for each class:  (array([0.7955707 , 0.31516184]), array([0.53739931, 0.60655738]), array([0.64148352, 0.41479821]), array([869, 305]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.54      0.80      0.64       587\n",
      "    constructive       0.61      0.32      0.41       587\n",
      "\n",
      "     avg / total       0.57      0.56      0.53      1174\n",
      "\n",
      "Results: \n",
      "macro_average => (0.555366269165247, 0.5719783433001944, 0.5281408613807717, None)\n",
      "weighted_average => (0.6707626048773976, 0.555366269165247, 0.5825916769497224, None)\n",
      "micro_average => (0.555366269165247, 0.555366269165247, 0.555366269165247, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['length_feats']\n",
      "TRAINING ON  (10623, 37)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['length_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  10623 \tConstructive ( 5870 ) \tNon constructive ( 4753 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.5468483816013628\n",
      "Precision-recall for each class:  (array([0.64054514, 0.45315162]), array([0.53945481, 0.55765199]), array([0.58566978, 0.5       ]), array([697, 477]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.54      0.64      0.59       587\n",
      "    constructive       0.56      0.45      0.50       587\n",
      "\n",
      "     avg / total       0.55      0.55      0.54      1174\n",
      "\n",
      "Results: \n",
      "macro_average => (0.546848381601363, 0.5485533989635123, 0.5428348909657321, None)\n",
      "weighted_average => (0.5644065484706983, 0.5468483816013628, 0.5508618722369936, None)\n",
      "micro_average => (0.5468483816013628, 0.5468483816013628, 0.5468483816013628, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['argumentation_feats']\n",
      "TRAINING ON  (10623, 37)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['argumentation_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  10623 \tConstructive ( 5870 ) \tNon constructive ( 4753 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.504258943781942\n",
      "Precision-recall for each class:  (array([0.50255537, 0.50596252]), array([0.5042735 , 0.50424448]), array([0.50341297, 0.50510204]), array([585, 589]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.50      0.50      0.50       587\n",
      "    constructive       0.50      0.51      0.51       587\n",
      "\n",
      "     avg / total       0.50      0.50      0.50      1174\n",
      "\n",
      "Results: \n",
      "macro_average => (0.504258943781942, 0.5042589932233396, 0.5042575050498013, None)\n",
      "weighted_average => (0.5042647481346261, 0.504258943781942, 0.5042603825140825, None)\n",
      "micro_average => (0.504258943781942, 0.504258943781942, 0.504258943781942, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['named_entity_feats']\n",
      "TRAINING ON  (10623, 37)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['named_entity_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  10623 \tConstructive ( 5870 ) \tNon constructive ( 4753 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.48211243611584326\n",
      "Precision-recall for each class:  (array([0.66780239, 0.29642249]), array([0.48695652, 0.47154472]), array([0.56321839, 0.36401674]), array([805, 369]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.49      0.67      0.56       587\n",
      "    constructive       0.47      0.30      0.36       587\n",
      "\n",
      "     avg / total       0.48      0.48      0.46      1174\n",
      "\n",
      "Results: \n",
      "macro_average => (0.48211243611584326, 0.47925061859314244, 0.46361756360313566, None)\n",
      "weighted_average => (0.5510739503553715, 0.48211243611584326, 0.5006073086285509, None)\n",
      "micro_average => (0.48211243611584326, 0.48211243611584326, 0.48211243611584326, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['text_quality_feats']\n",
      "TRAINING ON  (10623, 37)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_quality_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  10623 \tConstructive ( 5870 ) \tNon constructive ( 4753 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.5724020442930153\n",
      "Precision-recall for each class:  (array([0.60477002, 0.54003407]), array([0.568     , 0.57741348]), array([0.58580858, 0.55809859]), array([625, 549]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.57      0.60      0.59       587\n",
      "    constructive       0.58      0.54      0.56       587\n",
      "\n",
      "     avg / total       0.57      0.57      0.57      1174\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5724020442930153, 0.5727067395264116, 0.5719535862036907, None)\n",
      "weighted_average => (0.5744974156119674, 0.5724020442930153, 0.5728505023823399, None)\n",
      "micro_average => (0.5724020442930153, 0.5724020442930153, 0.5724020442930153, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['perspective_content_value_feats']\n",
      "TRAINING ON  (10623, 37)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_content_value_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  10623 \tConstructive ( 5870 ) \tNon constructive ( 4753 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.5919931856899489\n",
      "Precision-recall for each class:  (array([0.58432709, 0.59965928]), array([0.59342561, 0.59060403]), array([0.5888412 , 0.59509721]), array([578, 596]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.59      0.58      0.59       587\n",
      "    constructive       0.59      0.60      0.60       587\n",
      "\n",
      "     avg / total       0.59      0.59      0.59      1174\n",
      "\n",
      "Results: \n",
      "macro_average => (0.591993185689949, 0.5920148161909848, 0.591969206099282, None)\n",
      "weighted_average => (0.5921107238318014, 0.5919931856899489, 0.5920171652806158, None)\n",
      "micro_average => (0.5919931856899489, 0.5919931856899489, 0.5919931856899489, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['perspective_aggressiveness_feats']\n",
      "TRAINING ON  (10623, 37)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_aggressiveness_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  10623 \tConstructive ( 5870 ) \tNon constructive ( 4753 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.5229982964224872\n",
      "Precision-recall for each class:  (array([0.30834753, 0.73764906]), array([0.54029851, 0.51609058]), array([0.39262473, 0.60729313]), array([335, 839]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.54      0.31      0.39       587\n",
      "    constructive       0.52      0.74      0.61       587\n",
      "\n",
      "     avg / total       0.53      0.52      0.50      1174\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: \n",
      "macro_average => (0.5229982964224873, 0.5281945457456461, 0.4999589282400294, None)\n",
      "weighted_average => (0.6151481996349062, 0.5229982964224872, 0.5460376646049451, None)\n",
      "micro_average => (0.5229982964224872, 0.5229982964224872, 0.5229982964224872, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['perspecitive_toxicity_feats']\n",
      "TRAINING ON  (10623, 37)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspecitive_toxicity_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  10623 \tConstructive ( 5870 ) \tNon constructive ( 4753 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.5229982964224872\n",
      "Precision-recall for each class:  (array([0.49914821, 0.54684838]), array([0.52415027, 0.52195122]), array([0.5113438 , 0.53410982]), array([559, 615]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.52      0.50      0.51       587\n",
      "    constructive       0.52      0.55      0.53       587\n",
      "\n",
      "     avg / total       0.52      0.52      0.52      1174\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5229982964224872, 0.523050743924255, 0.5227268107546179, None)\n",
      "weighted_average => (0.5241359495485665, 0.5229982964224872, 0.5232697820903567, None)\n",
      "micro_average => (0.5229982964224872, 0.5229982964224872, 0.5229982964224872, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['ngram_feats', 'tfidf_feats', 'pos_feats', 'length_feats', 'argumentation_feats', 'named_entity_feats', 'text_quality_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "TRAINING ON  (10623, 37)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['ngram_feats', 'tfidf_feats', 'pos_feats', 'length_feats', 'argumentation_feats', 'named_entity_feats', 'text_quality_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  10623 \tConstructive ( 5870 ) \tNon constructive ( 4753 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.5834752981260647\n",
      "Precision-recall for each class:  (array([0.6286201 , 0.53833049]), array([0.5765625, 0.5917603]), array([0.60146699, 0.56378234]), array([640, 534]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.58      0.63      0.60       587\n",
      "    constructive       0.59      0.54      0.56       587\n",
      "\n",
      "     avg / total       0.58      0.58      0.58      1174\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5834752981260647, 0.5841613998127341, 0.5826246649319831, None)\n",
      "weighted_average => (0.5875514047984584, 0.5834752981260647, 0.5843259313201463, None)\n",
      "micro_average => (0.5834752981260647, 0.5834752981260647, 0.5834752981260647, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_balanced_data(train_df, balanced_df, feat_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train: Subset of CTC  Test: Balanced dataset of CTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CTC_df = pd.read_csv(Config.CTC_FEATURES_FILE_PATH)\n",
    "CTC_df['comment_len'] = CTC_df['pp_comment_text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the data:  10762 \tConstructive ( 5906 ) \tNon constructive ( 4856 )\n",
      "IN experiments_utils...\n",
      "comments_col:  pp_comment_text\n",
      "Cross validation folds:  10\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['constructiveness_chars_feats', 'non_constructiveness_chars_feats']\n",
      "COMMENTS COL:  pp_comment_text\n"
     ]
    }
   ],
   "source": [
    "results = run_cross_validation_experiments(CTC_df, ['constructiveness_chars_feats', 'non_constructiveness_chars_feats'], scoring ='f1')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1 scores': array([0.88471392, 0.957795  , 0.9645507 , 0.94401378, 0.91080617,\n",
       "        0.90721649, 0.90686275, 0.85759494, 0.89789303, 0.91673537]),\n",
       " 'mean f1': 0.914818215526098,\n",
       " 'variance': 0.0009780787264181167}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10762, 56)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTC_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOWER:  10\n",
      "UPPER:  20\n",
      "Number of constructive samples:  11\n",
      "Number of non-constructive samples:  11\n",
      "LOWER:  20\n",
      "UPPER:  30\n",
      "Number of constructive samples:  33\n",
      "Number of non-constructive samples:  33\n",
      "LOWER:  30\n",
      "UPPER:  40\n",
      "Number of constructive samples:  78\n",
      "Number of non-constructive samples:  78\n",
      "LOWER:  40\n",
      "UPPER:  50\n",
      "Number of constructive samples:  282\n",
      "Number of non-constructive samples:  282\n",
      "LOWER:  50\n",
      "UPPER:  60\n",
      "Number of constructive samples:  46\n",
      "Number of non-constructive samples:  46\n",
      "LOWER:  60\n",
      "UPPER:  70\n",
      "Number of constructive samples:  11\n",
      "Number of non-constructive samples:  11\n",
      "LOWER:  70\n",
      "UPPER:  80\n",
      "Number of constructive samples:  5\n",
      "Number of non-constructive samples:  5\n"
     ]
    }
   ],
   "source": [
    "balanced_df = get_balanced_df(CTC_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(932, 56)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.to_csv(Config.TRAIN_PATH + 'length_balanced_CTC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = CTC_df[~CTC_df['comment_counter'].isin(balanced_df['comment_counter'].tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9830, 56)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE SET:  ['ngram_feats', 'tfidf_feats']\n",
      "TRAINING ON  (9830, 56)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['ngram_feats', 'tfidf_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  9830 \tConstructive ( 5440 ) \tNon constructive ( 4390 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  932 \tConstructive ( 466 ) \tNon constructive ( 466 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.5536480686695279\n",
      "Precision-recall for each class:  (array([0.7360515 , 0.37124464]), array([0.53930818, 0.58445946]), array([0.62250454, 0.45406824]), array([636, 296]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.54      0.74      0.62       466\n",
      "    constructive       0.58      0.37      0.45       466\n",
      "\n",
      "     avg / total       0.56      0.55      0.54       932\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5536480686695279, 0.5618838177800443, 0.538286389337449, None)\n",
      "weighted_average => (0.620190093757483, 0.5536480686695279, 0.5690097480016068, None)\n",
      "micro_average => (0.5536480686695279, 0.5536480686695279, 0.5536480686695279, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['pos_feats']\n",
      "TRAINING ON  (9830, 56)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['pos_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  9830 \tConstructive ( 5440 ) \tNon constructive ( 4390 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  932 \tConstructive ( 466 ) \tNon constructive ( 466 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.5611587982832618\n",
      "Precision-recall for each class:  (array([0.52145923, 0.60085837]), array([0.56643357, 0.55666004]), array([0.54301676, 0.57791538]), array([429, 503]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.57      0.52      0.54       466\n",
      "    constructive       0.56      0.60      0.58       466\n",
      "\n",
      "     avg / total       0.56      0.56      0.56       932\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5611587982832618, 0.5615468030974989, 0.5604660682267615, None)\n",
      "weighted_average => (0.5643109101291238, 0.5611587982832618, 0.5618515283397622, None)\n",
      "micro_average => (0.5611587982832618, 0.5611587982832618, 0.5611587982832618, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['length_feats']\n",
      "TRAINING ON  (9830, 56)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['length_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  9830 \tConstructive ( 5440 ) \tNon constructive ( 4390 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  932 \tConstructive ( 466 ) \tNon constructive ( 466 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.6148068669527897\n",
      "Precision-recall for each class:  (array([0.65450644, 0.5751073 ]), array([0.60636183, 0.62470862]), array([0.62951496, 0.59888268]), array([503, 429]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.61      0.65      0.63       466\n",
      "    constructive       0.62      0.58      0.60       466\n",
      "\n",
      "     avg / total       0.62      0.61      0.61       932\n",
      "\n",
      "Results: \n",
      "macro_average => (0.6148068669527897, 0.6155352268672348, 0.6141988227222674, None)\n",
      "weighted_average => (0.6179589787986516, 0.6148068669527897, 0.615414911183312, None)\n",
      "micro_average => (0.6148068669527897, 0.6148068669527897, 0.6148068669527897, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['argumentation_feats']\n",
      "TRAINING ON  (9830, 56)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['argumentation_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  9830 \tConstructive ( 5440 ) \tNon constructive ( 4390 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  932 \tConstructive ( 466 ) \tNon constructive ( 466 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.5\n",
      "Precision-recall for each class:  (array([0.48712446, 0.51287554]), array([0.5, 0.5]), array([0.49347826, 0.50635593]), array([454, 478]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.50      0.49      0.49       466\n",
      "    constructive       0.50      0.51      0.51       466\n",
      "\n",
      "     avg / total       0.50      0.50      0.50       932\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5, 0.5, 0.49991709653647753, None)\n",
      "weighted_average => (0.500331558879331, 0.5, 0.5000829034635225, None)\n",
      "micro_average => (0.5, 0.5, 0.5, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['named_entity_feats']\n",
      "TRAINING ON  (9830, 56)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['named_entity_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  9830 \tConstructive ( 5440 ) \tNon constructive ( 4390 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  932 \tConstructive ( 466 ) \tNon constructive ( 466 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.5010729613733905\n",
      "Precision-recall for each class:  (array([0.40772532, 0.5944206 ]), array([0.50131926, 0.50090416]), array([0.44970414, 0.54367026]), array([379, 553]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.50      0.41      0.45       466\n",
      "    constructive       0.50      0.59      0.54       466\n",
      "\n",
      "     avg / total       0.50      0.50      0.50       932\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5010729613733906, 0.5011117101728637, 0.4966872034887435, None)\n",
      "weighted_average => (0.5185005249682256, 0.5010729613733905, 0.5054587192580376, None)\n",
      "micro_average => (0.5010729613733905, 0.5010729613733905, 0.5010729613733905, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['text_quality_feats']\n",
      "TRAINING ON  (9830, 56)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_quality_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  9830 \tConstructive ( 5440 ) \tNon constructive ( 4390 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  932 \tConstructive ( 466 ) \tNon constructive ( 466 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.5997854077253219\n",
      "Precision-recall for each class:  (array([0.63090129, 0.56866953]), array([0.59393939, 0.60640732]), array([0.61186264, 0.58693245]), array([495, 437]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.59      0.63      0.61       466\n",
      "    constructive       0.61      0.57      0.59       466\n",
      "\n",
      "     avg / total       0.60      0.60      0.60       932\n",
      "\n",
      "Results: \n",
      "macro_average => (0.599785407725322, 0.6001733582969282, 0.5993975452388444, None)\n",
      "weighted_average => (0.6017218036803036, 0.5997854077253219, 0.6001732702117997, None)\n",
      "micro_average => (0.5997854077253219, 0.5997854077253219, 0.5997854077253219, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['perspective_content_value_feats']\n",
      "TRAINING ON  (9830, 56)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_content_value_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  9830 \tConstructive ( 5440 ) \tNon constructive ( 4390 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  932 \tConstructive ( 466 ) \tNon constructive ( 466 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.6040772532188842\n",
      "Precision-recall for each class:  (array([0.53218884, 0.67596567]), array([0.62155388, 0.59099437]), array([0.5734104 , 0.63063063]), array([399, 533]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.62      0.53      0.57       466\n",
      "    constructive       0.59      0.68      0.63       466\n",
      "\n",
      "     avg / total       0.61      0.60      0.60       932\n",
      "\n",
      "Results: \n",
      "macro_average => (0.6040772532188841, 0.6062741280969779, 0.602020517627454, None)\n",
      "weighted_average => (0.6144131407835842, 0.6040772532188842, 0.6061339888103142, None)\n",
      "micro_average => (0.6040772532188842, 0.6040772532188842, 0.6040772532188842, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['perspective_aggressiveness_feats']\n",
      "TRAINING ON  (9830, 56)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_aggressiveness_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  9830 \tConstructive ( 5440 ) \tNon constructive ( 4390 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  932 \tConstructive ( 466 ) \tNon constructive ( 466 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.528969957081545\n",
      "Precision-recall for each class:  (array([0.30901288, 0.74892704]), array([0.55172414, 0.52011923]), array([0.39614856, 0.61389622]), array([261, 671]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.55      0.31      0.40       466\n",
      "    constructive       0.52      0.75      0.61       466\n",
      "\n",
      "     avg / total       0.54      0.53      0.51       932\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5289699570815452, 0.5359216814841461, 0.5050223869131223, None)\n",
      "weighted_average => (0.6257321925251893, 0.528969957081545, 0.5529175272499678, None)\n",
      "micro_average => (0.528969957081545, 0.528969957081545, 0.528969957081545, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['perspecitive_toxicity_feats']\n",
      "TRAINING ON  (9830, 56)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspecitive_toxicity_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  9830 \tConstructive ( 5440 ) \tNon constructive ( 4390 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  932 \tConstructive ( 466 ) \tNon constructive ( 466 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.5032188841201717\n",
      "Precision-recall for each class:  (array([0.49141631, 0.51502146]), array([0.5032967 , 0.50314465]), array([0.49728556, 0.50901379]), array([455, 477]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.50      0.49      0.50       466\n",
      "    constructive       0.50      0.52      0.51       466\n",
      "\n",
      "     avg / total       0.50      0.50      0.50       932\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5032188841201717, 0.5032206786923767, 0.5031496724824209, None)\n",
      "weighted_average => (0.5034974856784984, 0.5032188841201717, 0.5032880957579223, None)\n",
      "micro_average => (0.5032188841201717, 0.5032188841201717, 0.5032188841201717, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['ngram_feats', 'tfidf_feats', 'pos_feats', 'length_feats', 'argumentation_feats', 'named_entity_feats', 'text_quality_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "TRAINING ON  (9830, 56)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['ngram_feats', 'tfidf_feats', 'pos_feats', 'length_feats', 'argumentation_feats', 'named_entity_feats', 'text_quality_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  9830 \tConstructive ( 5440 ) \tNon constructive ( 4390 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  932 \tConstructive ( 466 ) \tNon constructive ( 466 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.6072961373390557\n",
      "Precision-recall for each class:  (array([0.68454936, 0.53004292]), array([0.5929368 , 0.62690355]), array([0.63545817, 0.5744186 ]), array([538, 394]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.59      0.68      0.64       466\n",
      "    constructive       0.63      0.53      0.57       466\n",
      "\n",
      "     avg / total       0.61      0.61      0.60       932\n",
      "\n",
      "Results: \n",
      "macro_average => (0.6072961373390557, 0.609920178136735, 0.6049383859909201, None)\n",
      "weighted_average => (0.6192322569949713, 0.6072961373390557, 0.6096538886871916, None)\n",
      "micro_average => (0.6072961373390557, 0.6072961373390557, 0.6072961373390557, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_balanced_data(train_df, balanced_df, feat_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_sets_crowd_feats = [crowd_annotated_feats, \n",
    "                         ['constructiveness_chars_feats', 'non_constructiveness_chars_feats'],                         \n",
    "                         ['toxicity_chars_feats']\n",
    "                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE SET:  ['constructiveness_chars_feats', 'non_constructiveness_chars_feats', 'toxicity_chars_feats']\n",
      "TRAINING ON  (9830, 56)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['constructiveness_chars_feats', 'non_constructiveness_chars_feats', 'toxicity_chars_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  9830 \tConstructive ( 5440 ) \tNon constructive ( 4390 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  932 \tConstructive ( 466 ) \tNon constructive ( 466 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.8175965665236051\n",
      "Precision-recall for each class:  (array([0.80686695, 0.82832618]), array([0.8245614 , 0.81092437]), array([0.81561822, 0.81953291]), array([456, 476]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.82      0.81      0.82       466\n",
      "    constructive       0.81      0.83      0.82       466\n",
      "\n",
      "     avg / total       0.82      0.82      0.82       932\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8175965665236051, 0.8177428866283356, 0.8175755649815089, None)\n",
      "weighted_average => (0.8178268157453628, 0.8175965665236051, 0.8176175680657014, None)\n",
      "micro_average => (0.8175965665236051, 0.8175965665236051, 0.8175965665236051, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['constructiveness_chars_feats', 'non_constructiveness_chars_feats']\n",
      "TRAINING ON  (9830, 56)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['constructiveness_chars_feats', 'non_constructiveness_chars_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  9830 \tConstructive ( 5440 ) \tNon constructive ( 4390 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  932 \tConstructive ( 466 ) \tNon constructive ( 466 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.8272532188841202\n",
      "Precision-recall for each class:  (array([0.82618026, 0.82832618]), array([0.82795699, 0.82655246]), array([0.82706767, 0.82743837]), array([465, 467]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.83      0.83      0.83       466\n",
      "    constructive       0.83      0.83      0.83       466\n",
      "\n",
      "     avg / total       0.83      0.83      0.83       932\n",
      "\n",
      "Results: \n",
      "macro_average => (0.8272532188841202, 0.8272547258870393, 0.8272530200098317, None)\n",
      "weighted_average => (0.8272555213763377, 0.8272532188841202, 0.8272534177584088, None)\n",
      "micro_average => (0.8272532188841202, 0.8272532188841202, 0.8272532188841202, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['toxicity_chars_feats']\n",
      "TRAINING ON  (9830, 56)\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['toxicity_chars_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  9830 \tConstructive ( 5440 ) \tNon constructive ( 4390 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp.pkl\n",
      "Size of the data:  932 \tConstructive ( 466 ) \tNon constructive ( 466 )\n",
      "Performance on the balanced test set: \n",
      "Accuracy:  0.5107296137339056\n",
      "Precision-recall for each class:  (array([0.05364807, 0.96781116]), array([0.625     , 0.50560538]), array([0.09881423, 0.66421208]), array([ 40, 892]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.62      0.05      0.10       466\n",
      "    constructive       0.51      0.97      0.66       466\n",
      "\n",
      "     avg / total       0.57      0.51      0.38       932\n",
      "\n",
      "Results: \n",
      "macro_average => (0.5107296137339056, 0.5653026905829597, 0.3815131529161112, None)\n",
      "weighted_average => (0.928576691410783, 0.5107296137339055, 0.6399460745516999, None)\n",
      "micro_average => (0.5107296137339056, 0.5107296137339056, 0.5107296137339056, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_balanced_data(train_df, balanced_df, feat_sets_crowd_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Config.ALL_DATASETS_ALL_FEATURES_FILE_PATH)\n",
    "NYT_YNC_df = df[df['source'].isin(['NYTPicks', 'YNACC'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE SET:  ['ngram_feats', 'tfidf_feats']\n",
      "TRAINING ON NYT YNC subset...\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['ngram_feats', 'tfidf_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  30325 \tConstructive ( 15147 ) \tNon constructive ( 15178 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/nyt_ync_svm.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on SOCC: \n",
      "Accuracy:  0.5945485519591142\n",
      "Precision-recall for each class:  (array([0.81771721, 0.3713799 ]), array([0.56537102, 0.67076923]), array([0.66852368, 0.47807018]), array([849, 325]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.57      0.82      0.67       587\n",
      "    constructive       0.67      0.37      0.48       587\n",
      "\n",
      "     avg / total       0.62      0.59      0.57      1174\n",
      "\n",
      "Results: \n",
      "weighted_average => (0.694157048370573, 0.5945485519591142, 0.6158001777588186, None)\n",
      "micro_average => (0.5945485519591142, 0.5945485519591142, 0.5945485519591142, None)\n",
      "macro_average => (0.5945485519591142, 0.6180701277521066, 0.5732969261594096, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['pos_feats']\n",
      "TRAINING ON NYT YNC subset...\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['pos_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  30325 \tConstructive ( 15147 ) \tNon constructive ( 15178 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/nyt_ync_svm.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on SOCC: \n",
      "Accuracy:  0.5477001703577513\n",
      "Precision-recall for each class:  (array([0.83475298, 0.26064736]), array([0.53030303, 0.612     ]), array([0.6485771, 0.3655914]), array([924, 250]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.53      0.83      0.65       587\n",
      "    constructive       0.61      0.26      0.37       587\n",
      "\n",
      "     avg / total       0.57      0.55      0.51      1174\n",
      "\n",
      "Results: \n",
      "weighted_average => (0.7124988028522589, 0.5477001703577513, 0.5883160911620486, None)\n",
      "micro_average => (0.5477001703577513, 0.5477001703577513, 0.5477001703577513, None)\n",
      "macro_average => (0.5477001703577513, 0.5711515151515152, 0.5070842495534539, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['length_feats']\n",
      "TRAINING ON NYT YNC subset...\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['length_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  30325 \tConstructive ( 15147 ) \tNon constructive ( 15178 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/nyt_ync_svm.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on SOCC: \n",
      "Accuracy:  0.5528109028960818\n",
      "Precision-recall for each class:  (array([0.89608177, 0.20954003]), array([0.53131313, 0.66847826]), array([0.66708941, 0.31906615]), array([990, 184]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.53      0.90      0.67       587\n",
      "    constructive       0.67      0.21      0.32       587\n",
      "\n",
      "     avg / total       0.60      0.55      0.49      1174\n",
      "\n",
      "Results: \n",
      "weighted_average => (0.7884806816631792, 0.5528109028960818, 0.6125440267258676, None)\n",
      "micro_average => (0.5528109028960818, 0.5528109028960818, 0.5528109028960818, None)\n",
      "macro_average => (0.5528109028960818, 0.5998956960913482, 0.4930777790662958, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['argumentation_feats']\n",
      "TRAINING ON NYT YNC subset...\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['argumentation_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  30325 \tConstructive ( 15147 ) \tNon constructive ( 15178 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/nyt_ync_svm.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on SOCC: \n",
      "Accuracy:  0.5110732538330494\n",
      "Precision-recall for each class:  (array([0.56899489, 0.45315162]), array([0.50992366, 0.51252408]), array([0.53784219, 0.48101266]), array([655, 519]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.51      0.57      0.54       587\n",
      "    constructive       0.51      0.45      0.48       587\n",
      "\n",
      "     avg / total       0.51      0.51      0.51      1174\n",
      "\n",
      "Results: \n",
      "weighted_average => (0.5177830855358433, 0.5110732538330494, 0.5127190835441233, None)\n",
      "micro_average => (0.5110732538330494, 0.5110732538330494, 0.5110732538330494, None)\n",
      "macro_average => (0.5110732538330494, 0.5112238744502787, 0.5094274241219756, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['named_entity_feats']\n",
      "TRAINING ON NYT YNC subset...\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['named_entity_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  30325 \tConstructive ( 15147 ) \tNon constructive ( 15178 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/nyt_ync_svm.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on SOCC: \n",
      "Accuracy:  0.4991482112436116\n",
      "Precision-recall for each class:  (array([0.69505963, 0.3032368 ]), array([0.499388  , 0.49859944]), array([0.58119658, 0.37711864]), array([817, 357]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.50      0.70      0.58       587\n",
      "    constructive       0.50      0.30      0.38       587\n",
      "\n",
      "     avg / total       0.50      0.50      0.48      1174\n",
      "\n",
      "Results: \n",
      "weighted_average => (0.5759107754905404, 0.4991482112436116, 0.5191388098550342, None)\n",
      "micro_average => (0.4991482112436116, 0.4991482112436116, 0.4991482112436116, None)\n",
      "macro_average => (0.4991482112436116, 0.49899372233593564, 0.4791576126321889, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['text_quality_feats']\n",
      "TRAINING ON NYT YNC subset...\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_quality_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  30325 \tConstructive ( 15147 ) \tNon constructive ( 15178 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/nyt_ync_svm.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on SOCC: \n",
      "Accuracy:  0.5562180579216355\n",
      "Precision-recall for each class:  (array([0.87223169, 0.24020443]), array([0.53444676, 0.65277778]), array([0.66278317, 0.35118306]), array([958, 216]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.53      0.87      0.66       587\n",
      "    constructive       0.65      0.24      0.35       587\n",
      "\n",
      "     avg / total       0.59      0.56      0.51      1174\n",
      "\n",
      "Results: \n",
      "weighted_average => (0.7559472848689232, 0.5562180579216355, 0.6054529983268377, None)\n",
      "micro_average => (0.5562180579216355, 0.5562180579216355, 0.5562180579216355, None)\n",
      "macro_average => (0.5562180579216355, 0.5936122709348179, 0.5069831175164331, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['perspective_content_value_feats']\n",
      "TRAINING ON NYT YNC subset...\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_content_value_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  30325 \tConstructive ( 15147 ) \tNon constructive ( 15178 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/nyt_ync_svm.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on SOCC: \n",
      "Accuracy:  0.6124361158432708\n",
      "Precision-recall for each class:  (array([0.67291312, 0.55195911]), array([0.60030395, 0.62790698]), array([0.63453815, 0.58748867]), array([658, 516]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.60      0.67      0.63       587\n",
      "    constructive       0.63      0.55      0.59       587\n",
      "\n",
      "     avg / total       0.61      0.61      0.61      1174\n",
      "\n",
      "Results: \n",
      "weighted_average => (0.6197510513133799, 0.6124361158432708, 0.6138588217457814, None)\n",
      "micro_average => (0.6124361158432708, 0.6124361158432708, 0.6124361158432708, None)\n",
      "macro_average => (0.6124361158432708, 0.6141054640559835, 0.6110134099407603, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['perspective_aggressiveness_feats']\n",
      "TRAINING ON NYT YNC subset...\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_aggressiveness_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  30325 \tConstructive ( 15147 ) \tNon constructive ( 15178 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/nyt_ync_svm.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on SOCC: \n",
      "Accuracy:  0.551107325383305\n",
      "Precision-recall for each class:  (array([0.439523  , 0.66269165]), array([0.56578947, 0.54178273]), array([0.49472675, 0.59616858]), array([456, 718]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.57      0.44      0.49       587\n",
      "    constructive       0.54      0.66      0.60       587\n",
      "\n",
      "     avg / total       0.55      0.55      0.55      1174\n",
      "\n",
      "Results: \n",
      "weighted_average => (0.5760094494861697, 0.551107325383305, 0.556766984698717, None)\n",
      "micro_average => (0.551107325383305, 0.551107325383305, 0.551107325383305, None)\n",
      "macro_average => (0.551107325383305, 0.5537861017446122, 0.5454476660678929, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['perspecitive_toxicity_feats']\n",
      "TRAINING ON NYT YNC subset...\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspecitive_toxicity_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  30325 \tConstructive ( 15147 ) \tNon constructive ( 15178 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/nyt_ync_svm.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on SOCC: \n",
      "Accuracy:  0.565587734241908\n",
      "Precision-recall for each class:  (array([0.62010221, 0.51107325]), array([0.55913978, 0.57361377]), array([0.58804523, 0.54054054]), array([651, 523]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.56      0.62      0.59       587\n",
      "    constructive       0.57      0.51      0.54       587\n",
      "\n",
      "     avg / total       0.57      0.57      0.56      1174\n",
      "\n",
      "Results: \n",
      "weighted_average => (0.5715313913904037, 0.565587734241908, 0.5668825810891516, None)\n",
      "micro_average => (0.565587734241908, 0.565587734241908, 0.565587734241908, None)\n",
      "macro_average => (0.565587734241908, 0.566376775838319, 0.5642928873946644, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n",
      "FEATURE SET:  ['ngram_feats', 'tfidf_feats', 'pos_feats', 'length_feats', 'argumentation_feats', 'named_entity_feats', 'text_quality_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "TRAINING ON NYT YNC subset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['ngram_feats', 'tfidf_feats', 'pos_feats', 'length_feats', 'argumentation_feats', 'named_entity_feats', 'text_quality_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "COMMENTS COL:  pp_comment_text\n",
      "Size of the training data:  30325 \tConstructive ( 15147 ) \tNon constructive ( 15178 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/nyt_ync_svm.pkl\n",
      "Size of the data:  1174 \tConstructive ( 587 ) \tNon constructive ( 587 )\n",
      "Performance on SOCC: \n",
      "Accuracy:  0.6192504258943782\n",
      "Precision-recall for each class:  (array([0.50085179, 0.73764906]), array([0.65625   , 0.59641873]), array([0.56811594, 0.65955826]), array([448, 726]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.66      0.50      0.57       587\n",
      "    constructive       0.60      0.74      0.66       587\n",
      "\n",
      "     avg / total       0.63      0.62      0.61      1174\n",
      "\n",
      "Results: \n",
      "weighted_average => (0.6472869004466449, 0.6192504258943782, 0.6246637490149338, None)\n",
      "micro_average => (0.6192504258943782, 0.6192504258943782, 0.6192504258943782, None)\n",
      "macro_average => (0.6192504258943782, 0.6263343663911846, 0.6138371027738225, None)\n",
      "<class 'dict'>\n",
      "\n",
      "\n",
      "**************************\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feat_set in feat_sets:\n",
    "    print('FEATURE SET: ', feat_set)\n",
    "    model_path = Config.MODEL_PATH + 'nyt_ync_svm.pkl'\n",
    "    print('TRAINING ON NYT YNC subset...')\n",
    "    train_and_save_model(NYT_YNC_df, model_path, feat_set)    \n",
    "    predicted, targets = get_predictions_with_model(model_path, balanced_df)\n",
    "    print('Performance on SOCC: ')\n",
    "    get_eval_results(predicted, targets)\n",
    "    \n",
    "    #predicted, targets = get_predictions_with_model(model_path, SOCC_df)\n",
    "    #print('Performance on SOCC: ')\n",
    "    #get_eval_results(predicted, targets)\n",
    "    print('\\n\\n**************************\\n\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [1, 45, 75,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOCC_df contains instances of annotated SOCC with the new annotation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOCC_df = training_feats_df[training_feats_df['source'] == 'SOCC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all_SOCC_df contains all instances of annotated SOCC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = SOCC_df['constructive'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_SOCC_df = training_feats_df[training_feats_df['source'].str.endswith('SOCC')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_results(avg_results_dict):\n",
    "    for feat_set, results_dict in avg_results_dict.items():\n",
    "        print('FEATURE SET: ', feat_set)\n",
    "        for (test_subset, res) in results_dict.items():\n",
    "            raw_html = '<h2>' + test_subset + '</h2>'\n",
    "            display(HTML(raw_html))\n",
    "            df = pd.DataFrame.from_dict(res, orient='index')\n",
    "                               #,columns=['Recall', 'Precision', 'F-score', 'Dummy'])\n",
    "            display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
