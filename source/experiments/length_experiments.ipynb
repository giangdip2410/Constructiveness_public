{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from config import Config\n",
    "from experiments_utils import *\n",
    "import pickle as pkl\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CSV containing comments and features from all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feats_file = Config.ALL_FEATURES_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feats_df = pd.read_csv(training_feats_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_feats_df['comment_len'] = training_feats_df['pp_comment_text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOCC_df contains instances of annotated SOCC with the new annotation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOCC_df = training_feats_df[training_feats_df['source'] == 'SOCC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all_SOCC_df contains all instances of annotated SOCC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_SOCC_df = training_feats_df[training_feats_df['source'].str.endswith('SOCC')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feats = ['text_feats']\n",
    "\n",
    "len_dependent_feats = ['length_feats',\n",
    "             'argumentation_feats',\n",
    "             'COMMENTIQ_feats',\n",
    "             'named_entity_feats']\n",
    "\n",
    "crowd_annotated_feats = ['constructiveness_chars_feats',\n",
    "                         'non_constructiveness_chars_feats',\n",
    "                         'toxicity_chars_feats']\n",
    "\n",
    "perspective_feats = ['perspective_content_value_feats',\n",
    "                     'perspective_aggressiveness_feats',\n",
    "                     'perspecitive_toxicity_feats']\n",
    "\n",
    "all_feats =  text_feats + len_dependent_feats + perspective_feats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_results(avg_results_dict):\n",
    "    for (test_subset, res) in avg_results_dict.items():\n",
    "        raw_html = '<h2>' + test_subset + '</h2>'\n",
    "        display(HTML(raw_html))\n",
    "        df = pd.DataFrame.from_dict(res, orient='index')\n",
    "                           #,columns=['Recall', 'Precision', 'F-score', 'Dummy'])\n",
    "        display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only length dependent feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  1\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10408\n",
      "Test samples:  2627\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4689 \tConstructive ( 2795 ) \tNon constructive ( 1894 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1201 \tConstructive ( 1014 ) \tNon constructive ( 187 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1254 \tConstructive ( 760 ) \tNon constructive ( 494 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  324 \tConstructive ( 278 ) \tNon constructive ( 46 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats']\n",
      "Size of the training data:  10408 \tConstructive ( 5129 ) \tNon constructive ( 5279 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2627 \tConstructive ( 1328 ) \tNon constructive ( 1299 )\n",
      "Accuracy:  0.9063570612866387\n",
      "Precision-recall for each class:  (array([0.90993072, 0.90286145]), array([0.90160183, 0.91109422]), array([0.90574713, 0.90695915]), array([1311, 1316]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.90      0.91      0.91      1299\n",
      "    constructive       0.91      0.90      0.91      1328\n",
      "\n",
      "     avg / total       0.91      0.91      0.91      2627\n",
      "\n",
      "Results: \n",
      "micro_average => (0.9063570612866387, 0.9063570612866387, 0.9063570612866387, None)\n",
      "weighted_average => (0.9063893533467174, 0.9063570612866387, 0.9063542930498013, None)\n",
      "macro_average => (0.9063960808592337, 0.9063480277938138, 0.9063531396177857, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1254 \tConstructive ( 760 ) \tNon constructive ( 494 )\n",
      "Accuracy:  0.8229665071770335\n",
      "Precision-recall for each class:  (array([0.7854251 , 0.84736842]), array([0.76984127, 0.85866667]), array([0.77755511, 0.85298013]), array([504, 750]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.77      0.79      0.78       494\n",
      "    constructive       0.86      0.85      0.85       760\n",
      "\n",
      "     avg / total       0.82      0.82      0.82      1254\n",
      "\n",
      "Results: \n",
      "micro_average => (0.8229665071770335, 0.8229665071770335, 0.8229665071770335, None)\n",
      "weighted_average => (0.8224725413091063, 0.8229665071770335, 0.8226657694488443, None)\n",
      "macro_average => (0.8163967611336032, 0.8142539682539682, 0.815267621335386, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  324 \tConstructive ( 278 ) \tNon constructive ( 46 )\n",
      "Accuracy:  0.4845679012345679\n",
      "Precision-recall for each class:  (array([0.       , 0.5647482]), array([0.        , 0.77339901]), array([0.        , 0.65280665]), array([121, 203]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        46\n",
      "    constructive       0.77      0.56      0.65       278\n",
      "\n",
      "     avg / total       0.66      0.48      0.56       324\n",
      "\n",
      "Results: \n",
      "micro_average => (0.4845679012345679, 0.4845679012345679, 0.48456790123456794, None)\n",
      "weighted_average => (0.35383915090150103, 0.4845679012345679, 0.4090115756782423, None)\n",
      "macro_average => (0.2823741007194245, 0.3866995073891626, 0.3264033264033264, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  2\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10433\n",
      "Test samples:  2602\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4744 \tConstructive ( 2843 ) \tNon constructive ( 1901 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1227 \tConstructive ( 1053 ) \tNon constructive ( 174 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1199 \tConstructive ( 712 ) \tNon constructive ( 487 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  298 \tConstructive ( 239 ) \tNon constructive ( 59 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats']\n",
      "Size of the training data:  10433 \tConstructive ( 5180 ) \tNon constructive ( 5253 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2602 \tConstructive ( 1277 ) \tNon constructive ( 1325 )\n",
      "Accuracy:  0.9108378170637971\n",
      "Precision-recall for each class:  (array([0.90943396, 0.91229444]), array([0.91495824, 0.90661479]), array([0.91218774, 0.90944575]), array([1317, 1285]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.91      0.91      1325\n",
      "    constructive       0.91      0.91      0.91      1277\n",
      "\n",
      "     avg / total       0.91      0.91      0.91      2602\n",
      "\n",
      "Results: \n",
      "micro_average => (0.9108378170637971, 0.9108378170637971, 0.9108378170637971, None)\n",
      "weighted_average => (0.9108466117688849, 0.9108378170637971, 0.9108336018584906, None)\n",
      "macro_average => (0.9108642011790606, 0.9107865122064355, 0.9108167410372645, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1199 \tConstructive ( 712 ) \tNon constructive ( 487 )\n",
      "Accuracy:  0.8340283569641368\n",
      "Precision-recall for each class:  (array([0.78234086, 0.86938202]), array([0.80379747, 0.8537931 ]), array([0.79292404, 0.86151705]), array([474, 725]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.80      0.78      0.79       487\n",
      "    constructive       0.85      0.87      0.86       712\n",
      "\n",
      "     avg / total       0.83      0.83      0.83      1199\n",
      "\n",
      "Results: \n",
      "micro_average => (0.8340283569641368, 0.8340283569641368, 0.8340283569641368, None)\n",
      "weighted_average => (0.8349720893082867, 0.8340283569641368, 0.8344002123249865, None)\n",
      "macro_average => (0.825861442447454, 0.8287952859013531, 0.827220543434734, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  298 \tConstructive ( 239 ) \tNon constructive ( 59 )\n",
      "Accuracy:  0.4261744966442953\n",
      "Precision-recall for each class:  (array([0.        , 0.53138075]), array([0.       , 0.6827957]), array([0.        , 0.59764706]), array([112, 186]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        59\n",
      "    constructive       0.68      0.53      0.60       239\n",
      "\n",
      "     avg / total       0.55      0.43      0.48       298\n",
      "\n",
      "Results: \n",
      "micro_average => (0.4261744966442953, 0.4261744966442953, 0.42617449664429524, None)\n",
      "weighted_average => (0.3316671814888658, 0.42617449664429524, 0.37302803000394785, None)\n",
      "macro_average => (0.26569037656903766, 0.34139784946236557, 0.2988235294117647, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  3\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10446\n",
      "Test samples:  2589\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4767 \tConstructive ( 2851 ) \tNon constructive ( 1916 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1217 \tConstructive ( 1038 ) \tNon constructive ( 179 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1176 \tConstructive ( 704 ) \tNon constructive ( 472 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  308 \tConstructive ( 254 ) \tNon constructive ( 54 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats']\n",
      "Size of the training data:  10446 \tConstructive ( 5187 ) \tNon constructive ( 5259 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2589 \tConstructive ( 1270 ) \tNon constructive ( 1319 )\n",
      "Accuracy:  0.9134801081498648\n",
      "Precision-recall for each class:  (array([0.91963609, 0.90708661]), array([0.91134485, 0.91573927]), array([0.9154717 , 0.91139241]), array([1331, 1258]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.92      0.92      1319\n",
      "    constructive       0.92      0.91      0.91      1270\n",
      "\n",
      "     avg / total       0.91      0.91      0.91      2589\n",
      "\n",
      "Results: \n",
      "micro_average => (0.9134801081498648, 0.9134801081498648, 0.9134801081498648, None)\n",
      "weighted_average => (0.9135382748880905, 0.9134801081498648, 0.9134895618996909, None)\n",
      "macro_average => (0.9133613510593208, 0.9135420610870295, 0.9134320515882492, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1176 \tConstructive ( 704 ) \tNon constructive ( 472 )\n",
      "Accuracy:  0.8367346938775511\n",
      "Precision-recall for each class:  (array([0.81144068, 0.85369318]), array([0.78806584, 0.87101449]), array([0.79958246, 0.86226686]), array([486, 690]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.79      0.81      0.80       472\n",
      "    constructive       0.87      0.85      0.86       704\n",
      "\n",
      "     avg / total       0.84      0.84      0.84      1176\n",
      "\n",
      "Results: \n",
      "micro_average => (0.8367346938775511, 0.8367346938775511, 0.8367346938775511, None)\n",
      "weighted_average => (0.8362316878793119, 0.8367346938775511, 0.8363615724817347, None)\n",
      "macro_average => (0.8325669298921416, 0.8295401681875112, 0.8309246607141252, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  308 \tConstructive ( 254 ) \tNon constructive ( 54 )\n",
      "Accuracy:  0.44155844155844154\n",
      "Precision-recall for each class:  (array([0.        , 0.53543307]), array([0.        , 0.71578947]), array([0.        , 0.61261261]), array([118, 190]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        54\n",
      "    constructive       0.72      0.54      0.61       254\n",
      "\n",
      "     avg / total       0.59      0.44      0.51       308\n",
      "\n",
      "Results: \n",
      "micro_average => (0.44155844155844154, 0.44155844155844154, 0.44155844155844154, None)\n",
      "weighted_average => (0.3302996216382043, 0.44155844155844154, 0.37791037791037796, None)\n",
      "macro_average => (0.2677165354330709, 0.35789473684210527, 0.30630630630630634, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  4\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10389\n",
      "Test samples:  2646\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4699 \tConstructive ( 2789 ) \tNon constructive ( 1910 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1199 \tConstructive ( 1017 ) \tNon constructive ( 182 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1244 \tConstructive ( 766 ) \tNon constructive ( 478 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  326 \tConstructive ( 275 ) \tNon constructive ( 51 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats']\n",
      "Size of the training data:  10389 \tConstructive ( 5122 ) \tNon constructive ( 5267 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2646 \tConstructive ( 1335 ) \tNon constructive ( 1311 )\n",
      "Accuracy:  0.9176114890400605\n",
      "Precision-recall for each class:  (array([0.93135011, 0.90411985]), array([0.9051149, 0.9306091]), array([0.91804511, 0.91717325]), array([1349, 1297]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.93      0.92      1311\n",
      "    constructive       0.93      0.90      0.92      1335\n",
      "\n",
      "     avg / total       0.92      0.92      0.92      2646\n",
      "\n",
      "Results: \n",
      "micro_average => (0.9176114890400605, 0.9176114890400605, 0.9176114890400605, None)\n",
      "weighted_average => (0.9180025510357935, 0.9176114890400605, 0.9176177495652095, None)\n",
      "macro_average => (0.917734982301871, 0.917861998922072, 0.9176091825307952, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1244 \tConstructive ( 766 ) \tNon constructive ( 478 )\n",
      "Accuracy:  0.8408360128617364\n",
      "Precision-recall for each class:  (array([0.83054393, 0.84725849]), array([0.77237354, 0.8890411 ]), array([0.80040323, 0.86764706]), array([514, 730]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.77      0.83      0.80       478\n",
      "    constructive       0.89      0.85      0.87       766\n",
      "\n",
      "     avg / total       0.84      0.84      0.84      1244\n",
      "\n",
      "Results: \n",
      "micro_average => (0.8408360128617364, 0.8408360128617364, 0.8408360128617364, None)\n",
      "weighted_average => (0.8403523119830623, 0.8408360128617364, 0.8398630313550582, None)\n",
      "macro_average => (0.83890120934704, 0.830707318373221, 0.8340251423149905, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  326 \tConstructive ( 275 ) \tNon constructive ( 51 )\n",
      "Accuracy:  0.450920245398773\n",
      "Precision-recall for each class:  (array([0.        , 0.53454545]), array([0.        , 0.74242424]), array([0.        , 0.62156448]), array([128, 198]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        51\n",
      "    constructive       0.74      0.53      0.62       275\n",
      "\n",
      "     avg / total       0.63      0.45      0.52       326\n",
      "\n",
      "Results: \n",
      "micro_average => (0.450920245398773, 0.450920245398773, 0.450920245398773, None)\n",
      "weighted_average => (0.32466257668711657, 0.450920245398773, 0.37751462405478675, None)\n",
      "macro_average => (0.2672727272727273, 0.3712121212121212, 0.3107822410147992, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  5\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10419\n",
      "Test samples:  2616\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4737 \tConstructive ( 2811 ) \tNon constructive ( 1926 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1213 \tConstructive ( 1023 ) \tNon constructive ( 190 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1206 \tConstructive ( 744 ) \tNon constructive ( 462 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  312 \tConstructive ( 269 ) \tNon constructive ( 43 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['length_feats', 'argumentation_feats', 'COMMENTIQ_feats', 'named_entity_feats']\n",
      "Size of the training data:  10419 \tConstructive ( 5126 ) \tNon constructive ( 5293 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2616 \tConstructive ( 1331 ) \tNon constructive ( 1285 )\n",
      "Accuracy:  0.9159021406727829\n",
      "Precision-recall for each class:  (array([0.93229572, 0.90007513]), array([0.90007513, 0.93229572]), array([0.91590214, 0.91590214]), array([1331, 1285]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.90      0.93      0.92      1285\n",
      "    constructive       0.93      0.90      0.92      1331\n",
      "\n",
      "     avg / total       0.92      0.92      0.92      2616\n",
      "\n",
      "Results: \n",
      "micro_average => (0.9159021406727829, 0.9159021406727829, 0.9159021406727829, None)\n",
      "weighted_average => (0.9164687106516652, 0.9159021406727829, 0.9159021406727829, None)\n",
      "macro_average => (0.916185425662224, 0.916185425662224, 0.9159021406727829, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1206 \tConstructive ( 744 ) \tNon constructive ( 462 )\n",
      "Accuracy:  0.8424543946932007\n",
      "Precision-recall for each class:  (array([0.83549784, 0.84677419]), array([0.772     , 0.89235127]), array([0.8024948 , 0.86896552]), array([500, 706]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.77      0.84      0.80       462\n",
      "    constructive       0.89      0.85      0.87       744\n",
      "\n",
      "     avg / total       0.85      0.84      0.84      1206\n",
      "\n",
      "Results: \n",
      "micro_average => (0.8424543946932007, 0.8424543946932007, 0.8424543946932007, None)\n",
      "weighted_average => (0.8420990865622546, 0.8424543946932007, 0.8414071777942081, None)\n",
      "macro_average => (0.8411360145231113, 0.8321756373937677, 0.8357301598680908, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  312 \tConstructive ( 269 ) \tNon constructive ( 43 )\n",
      "Accuracy:  0.4423076923076923\n",
      "Precision-recall for each class:  (array([0.04651163, 0.50557621]), array([0.01481481, 0.76836158]), array([0.02247191, 0.60986547]), array([135, 177]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.01      0.05      0.02        43\n",
      "    constructive       0.77      0.51      0.61       269\n",
      "\n",
      "     avg / total       0.66      0.44      0.53       312\n",
      "\n",
      "Results: \n",
      "micro_average => (0.4423076923076923, 0.4423076923076923, 0.4423076923076923, None)\n",
      "weighted_average => (0.30694249556097913, 0.4423076923076923, 0.35570479553197343, None)\n",
      "macro_average => (0.27604391804270767, 0.3915881983678594, 0.31616869048218876, None)\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "feature_set = len_dependent_feats\n",
    "avg_results_len_dict = run_n_experiments(all_SOCC_df, feature_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>test_all</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.912945</td>\n",
       "      <td>0.912823</td>\n",
       "      <td>0.912908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.912838</td>\n",
       "      <td>0.912838</td>\n",
       "      <td>0.912838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.912838</td>\n",
       "      <td>0.912839</td>\n",
       "      <td>0.913049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_balanced</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.827094</td>\n",
       "      <td>0.828634</td>\n",
       "      <td>0.830972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.835404</td>\n",
       "      <td>0.835404</td>\n",
       "      <td>0.835404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.835404</td>\n",
       "      <td>0.834940</td>\n",
       "      <td>0.835226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_hard</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.369758</td>\n",
       "      <td>0.311697</td>\n",
       "      <td>0.271820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.449106</td>\n",
       "      <td>0.449106</td>\n",
       "      <td>0.449106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.449106</td>\n",
       "      <td>0.378634</td>\n",
       "      <td>0.329482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print_results(avg_results_len_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only perspective features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  1\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10423\n",
      "Test samples:  2612\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4751 \tConstructive ( 2819 ) \tNon constructive ( 1932 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1210 \tConstructive ( 1012 ) \tNon constructive ( 198 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1192 \tConstructive ( 736 ) \tNon constructive ( 456 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  315 \tConstructive ( 280 ) \tNon constructive ( 35 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  10423 \tConstructive ( 5135 ) \tNon constructive ( 5288 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2612 \tConstructive ( 1322 ) \tNon constructive ( 1290 )\n",
      "Accuracy:  0.8847626339969372\n",
      "Precision-recall for each class:  (array([0.86589147, 0.903177  ]), array([0.89718876, 0.8734455 ]), array([0.88126233, 0.88806248]), array([1245, 1367]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.90      0.87      0.88      1290\n",
      "    constructive       0.87      0.90      0.89      1322\n",
      "\n",
      "     avg / total       0.89      0.88      0.88      2612\n",
      "\n",
      "Results: \n",
      "micro_average => (0.8847626339969372, 0.8847626339969372, 0.8847626339969372, None)\n",
      "weighted_average => (0.8854049957600177, 0.8847626339969372, 0.8848212110873553, None)\n",
      "macro_average => (0.8845342387033975, 0.8853171280586869, 0.8846624020866661, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1192 \tConstructive ( 736 ) \tNon constructive ( 456 )\n",
      "Accuracy:  0.7810402684563759\n",
      "Precision-recall for each class:  (array([0.6622807 , 0.85461957]), array([0.73838631, 0.80332056]), array([0.6982659 , 0.82817643]), array([409, 783]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.74      0.66      0.70       456\n",
      "    constructive       0.80      0.85      0.83       736\n",
      "\n",
      "     avg / total       0.78      0.78      0.78      1192\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7810402684563759, 0.7810402684563759, 0.7810402684563759, None)\n",
      "weighted_average => (0.7886240994821822, 0.7810402684563759, 0.7836014241559301, None)\n",
      "macro_average => (0.7584501334858886, 0.7708534350048556, 0.7632211639084125, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  315 \tConstructive ( 280 ) \tNon constructive ( 35 )\n",
      "Accuracy:  0.6253968253968254\n",
      "Precision-recall for each class:  (array([0.25714286, 0.67142857]), array([0.08910891, 0.87850467]), array([0.13235294, 0.7611336 ]), array([101, 214]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.09      0.26      0.13        35\n",
      "    constructive       0.88      0.67      0.76       280\n",
      "\n",
      "     avg / total       0.79      0.63      0.69       315\n",
      "\n",
      "Results: \n",
      "micro_average => (0.6253968253968254, 0.6253968253968254, 0.6253968253968254, None)\n",
      "weighted_average => (0.5385941043083899, 0.6253968253968254, 0.5595245655617173, None)\n",
      "macro_average => (0.46428571428571425, 0.48380679189414266, 0.44674327220766846, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  2\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10370\n",
      "Test samples:  2665\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4706 \tConstructive ( 2827 ) \tNon constructive ( 1879 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1213 \tConstructive ( 1025 ) \tNon constructive ( 188 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1237 \tConstructive ( 728 ) \tNon constructive ( 509 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  312 \tConstructive ( 267 ) \tNon constructive ( 45 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  10370 \tConstructive ( 5147 ) \tNon constructive ( 5223 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2665 \tConstructive ( 1310 ) \tNon constructive ( 1355 )\n",
      "Accuracy:  0.8787992495309569\n",
      "Precision-recall for each class:  (array([0.84575646, 0.9129771 ]), array([0.90952381, 0.85124555]), array([0.87648184, 0.88103131]), array([1260, 1405]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.85      0.88      1355\n",
      "    constructive       0.85      0.91      0.88      1310\n",
      "\n",
      "     avg / total       0.88      0.88      0.88      2665\n",
      "\n",
      "Results: \n",
      "micro_average => (0.8787992495309569, 0.8787992495309569, 0.8787992495309569, None)\n",
      "weighted_average => (0.8811954825361524, 0.8787992495309569, 0.8788803376808116, None)\n",
      "macro_average => (0.8793667784006085, 0.8803846805626165, 0.8787565715573491, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1237 \tConstructive ( 728 ) \tNon constructive ( 509 )\n",
      "Accuracy:  0.7801131770412287\n",
      "Precision-recall for each class:  (array([0.65422397, 0.86813187]), array([0.77622378, 0.78217822]), array([0.71002132, 0.82291667]), array([429, 808]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.78      0.65      0.71       509\n",
      "    constructive       0.78      0.87      0.82       728\n",
      "\n",
      "     avg / total       0.78      0.78      0.78      1237\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7801131770412287, 0.7801131770412287, 0.7801131770412286, None)\n",
      "weighted_average => (0.7939471559945709, 0.7801131770412287, 0.7837637944932916, None)\n",
      "macro_average => (0.7611779183488417, 0.7792009970227792, 0.7664689943141435, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  312 \tConstructive ( 267 ) \tNon constructive ( 45 )\n",
      "Accuracy:  0.6410256410256411\n",
      "Precision-recall for each class:  (array([0.13333333, 0.72659176]), array([0.07594937, 0.83261803]), array([0.09677419, 0.776     ]), array([ 79, 233]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.08      0.13      0.10        45\n",
      "    constructive       0.83      0.73      0.78       267\n",
      "\n",
      "     avg / total       0.72      0.64      0.68       312\n",
      "\n",
      "Results: \n",
      "micro_average => (0.6410256410256411, 0.6410256410256411, 0.6410256410256411, None)\n",
      "weighted_average => (0.5763756842408528, 0.6410256410256411, 0.6040165425971877, None)\n",
      "macro_average => (0.4299625468164794, 0.45428369641984023, 0.4363870967741935, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  3\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10482\n",
      "Test samples:  2553\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4798 \tConstructive ( 2845 ) \tNon constructive ( 1953 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1247 \tConstructive ( 1058 ) \tNon constructive ( 189 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1145 \tConstructive ( 710 ) \tNon constructive ( 435 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  278 \tConstructive ( 234 ) \tNon constructive ( 44 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  10482 \tConstructive ( 5171 ) \tNon constructive ( 5311 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2553 \tConstructive ( 1286 ) \tNon constructive ( 1267 )\n",
      "Accuracy:  0.8852330591461026\n",
      "Precision-recall for each class:  (array([0.851618  , 0.91835148]), array([0.91131757, 0.86267348]), array([0.88045696, 0.88964218]), array([1184, 1369]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.85      0.88      1267\n",
      "    constructive       0.86      0.92      0.89      1286\n",
      "\n",
      "     avg / total       0.89      0.89      0.89      2553\n",
      "\n",
      "Results: \n",
      "micro_average => (0.8852330591461026, 0.8852330591461026, 0.8852330591461026, None)\n",
      "weighted_average => (0.8874026161462433, 0.8852330591461026, 0.8853823685745568, None)\n",
      "macro_average => (0.8849847363569299, 0.8869955259313367, 0.885049570450894, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1145 \tConstructive ( 710 ) \tNon constructive ( 435 )\n",
      "Accuracy:  0.7755458515283843\n",
      "Precision-recall for each class:  (array([0.62758621, 0.86619718]), array([0.74184783, 0.79150579]), array([0.67995019, 0.8271688 ]), array([368, 777]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.74      0.63      0.68       435\n",
      "    constructive       0.79      0.87      0.83       710\n",
      "\n",
      "     avg / total       0.77      0.78      0.77      1145\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7755458515283843, 0.7755458515283843, 0.7755458515283843, None)\n",
      "weighted_average => (0.7895082405288529, 0.7755458515283843, 0.7798531208873857, None)\n",
      "macro_average => (0.7468916949975717, 0.766676808796374, 0.753559491516765, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  278 \tConstructive ( 234 ) \tNon constructive ( 44 )\n",
      "Accuracy:  0.6187050359712231\n",
      "Precision-recall for each class:  (array([0.18181818, 0.7008547 ]), array([0.1025641, 0.82     ]), array([0.13114754, 0.75576037]), array([ 78, 200]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.10      0.18      0.13        44\n",
      "    constructive       0.82      0.70      0.76       234\n",
      "\n",
      "     avg / total       0.71      0.62      0.66       278\n",
      "\n",
      "Results: \n",
      "micro_average => (0.6187050359712231, 0.6187050359712231, 0.6187050359712231, None)\n",
      "weighted_average => (0.5552257494703537, 0.6187050359712231, 0.5805092875159719, None)\n",
      "macro_average => (0.44133644133644134, 0.46128205128205124, 0.4434539548236005, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  4\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10439\n",
      "Test samples:  2596\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the data:  4748 \tConstructive ( 2823 ) \tNon constructive ( 1925 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1222 \tConstructive ( 1040 ) \tNon constructive ( 182 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1195 \tConstructive ( 732 ) \tNon constructive ( 463 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  303 \tConstructive ( 252 ) \tNon constructive ( 51 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  10439 \tConstructive ( 5180 ) \tNon constructive ( 5259 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2596 \tConstructive ( 1277 ) \tNon constructive ( 1319 )\n",
      "Accuracy:  0.8705701078582434\n",
      "Precision-recall for each class:  (array([0.84230478, 0.89976507]), array([0.89669088, 0.84672071]), array([0.86864738, 0.87243736]), array([1239, 1357]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.90      0.84      0.87      1319\n",
      "    constructive       0.85      0.90      0.87      1277\n",
      "\n",
      "     avg / total       0.87      0.87      0.87      2596\n",
      "\n",
      "Results: \n",
      "micro_average => (0.8705701078582434, 0.8705701078582434, 0.8705701078582434, None)\n",
      "weighted_average => (0.872340841234126, 0.8705701078582434, 0.8706285050364369, None)\n",
      "macro_average => (0.8710349253694126, 0.871705793592308, 0.8705423691986016, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1195 \tConstructive ( 732 ) \tNon constructive ( 463 )\n",
      "Accuracy:  0.7573221757322176\n",
      "Precision-recall for each class:  (array([0.61771058, 0.84562842]), array([0.71679198, 0.77763819]), array([0.66357309, 0.81020942]), array([399, 796]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.72      0.62      0.66       463\n",
      "    constructive       0.78      0.85      0.81       732\n",
      "\n",
      "     avg / total       0.75      0.76      0.75      1195\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7573221757322176, 0.7573221757322176, 0.7573221757322176, None)\n",
      "weighted_average => (0.7695286537719, 0.7573221757322176, 0.7612488391829126, None)\n",
      "macro_average => (0.731669499226947, 0.7472150854523243, 0.7368912549653186, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  303 \tConstructive ( 252 ) \tNon constructive ( 51 )\n",
      "Accuracy:  0.5643564356435643\n",
      "Precision-recall for each class:  (array([0.17647059, 0.64285714]), array([0.09090909, 0.79411765]), array([0.12      , 0.71052632]), array([ 99, 204]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.09      0.18      0.12        51\n",
      "    constructive       0.79      0.64      0.71       252\n",
      "\n",
      "     avg / total       0.68      0.56      0.61       303\n",
      "\n",
      "Results: \n",
      "micro_average => (0.5643564356435643, 0.5643564356435643, 0.5643564356435643, None)\n",
      "weighted_average => (0.4904734170896081, 0.5643564356435643, 0.5175820739968734, None)\n",
      "macro_average => (0.40966386554621853, 0.4425133689839572, 0.41526315789473683, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  5\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10416\n",
      "Test samples:  2619\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4754 \tConstructive ( 2864 ) \tNon constructive ( 1890 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1244 \tConstructive ( 1054 ) \tNon constructive ( 190 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1189 \tConstructive ( 691 ) \tNon constructive ( 498 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  281 \tConstructive ( 238 ) \tNon constructive ( 43 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  10416 \tConstructive ( 5192 ) \tNon constructive ( 5224 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2619 \tConstructive ( 1265 ) \tNon constructive ( 1354 )\n",
      "Accuracy:  0.8717067583046965\n",
      "Precision-recall for each class:  (array([0.83899557, 0.90671937]), array([0.90590112, 0.84029304]), array([0.87116564, 0.87224335]), array([1254, 1365]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.84      0.87      1354\n",
      "    constructive       0.84      0.91      0.87      1265\n",
      "\n",
      "     avg / total       0.87      0.87      0.87      2619\n",
      "\n",
      "Results: \n",
      "micro_average => (0.8717067583046965, 0.8717067583046965, 0.8717067583046965, None)\n",
      "weighted_average => (0.8742926230967374, 0.8717067583046965, 0.8717273329865564, None)\n",
      "macro_average => (0.8728574681371547, 0.8730970783602363, 0.8717044950896918, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1189 \tConstructive ( 691 ) \tNon constructive ( 498 )\n",
      "Accuracy:  0.7510513036164844\n",
      "Precision-recall for each class:  (array([0.61044177, 0.85238784]), array([0.74876847, 0.75223499]), array([0.67256637, 0.79918589]), array([406, 783]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.75      0.61      0.67       498\n",
      "    constructive       0.75      0.85      0.80       691\n",
      "\n",
      "     avg / total       0.75      0.75      0.75      1189\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7510513036164844, 0.7510513036164844, 0.7510513036164844, None)\n",
      "weighted_average => (0.7697721102191407, 0.7510513036164844, 0.7559499560846161, None)\n",
      "macro_average => (0.7314148053865244, 0.7505017332603539, 0.7358761302097717, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  281 \tConstructive ( 238 ) \tNon constructive ( 43 )\n",
      "Accuracy:  0.6014234875444839\n",
      "Precision-recall for each class:  (array([0.25581395, 0.66386555]), array([0.12087912, 0.83157895]), array([0.1641791 , 0.73831776]), array([ 91, 190]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.12      0.26      0.16        43\n",
      "    constructive       0.83      0.66      0.74       238\n",
      "\n",
      "     avg / total       0.72      0.60      0.65       281\n",
      "\n",
      "Results: \n",
      "micro_average => (0.6014234875444839, 0.6014234875444839, 0.6014234875444839, None)\n",
      "weighted_average => (0.5317207243735034, 0.6014234875444839, 0.5523867343033395, None)\n",
      "macro_average => (0.45983974985342974, 0.476229034123771, 0.45124843074347887, None)\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "feature_set = perspective_feats\n",
    "avg_results_perspective_dict = run_n_experiments(all_SOCC_df, feature_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>test_all</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.879500</td>\n",
       "      <td>0.878143</td>\n",
       "      <td>0.878556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.878214</td>\n",
       "      <td>0.878214</td>\n",
       "      <td>0.878214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.878214</td>\n",
       "      <td>0.878288</td>\n",
       "      <td>0.880127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_balanced</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.762890</td>\n",
       "      <td>0.751203</td>\n",
       "      <td>0.745921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.769015</td>\n",
       "      <td>0.769015</td>\n",
       "      <td>0.769015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.769015</td>\n",
       "      <td>0.772883</td>\n",
       "      <td>0.782276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_hard</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.463623</td>\n",
       "      <td>0.438619</td>\n",
       "      <td>0.441018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.610181</td>\n",
       "      <td>0.610181</td>\n",
       "      <td>0.610181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.610181</td>\n",
       "      <td>0.562804</td>\n",
       "      <td>0.538478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print_results(avg_results_perspective_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  1\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10430\n",
      "Test samples:  2605\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4786 \tConstructive ( 2837 ) \tNon constructive ( 1949 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1222 \tConstructive ( 1031 ) \tNon constructive ( 191 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1157 \tConstructive ( 718 ) \tNon constructive ( 439 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  303 \tConstructive ( 261 ) \tNon constructive ( 42 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats']\n",
      "Size of the training data:  10430 \tConstructive ( 5176 ) \tNon constructive ( 5254 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2605 \tConstructive ( 1281 ) \tNon constructive ( 1324 )\n",
      "Accuracy:  0.7650671785028791\n",
      "Precision-recall for each class:  (array([0.55740181, 0.97970336]), array([0.96596859, 0.68169473]), array([0.70689655, 0.80397181]), array([ 764, 1841]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.97      0.56      0.71      1324\n",
      "    constructive       0.68      0.98      0.80      1281\n",
      "\n",
      "     avg / total       0.83      0.77      0.75      2605\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7650671785028791, 0.7650671785028791, 0.7650671785028791, None)\n",
      "weighted_average => (0.855849852082795, 0.7650671785028791, 0.7755013716470479, None)\n",
      "macro_average => (0.7685525847206793, 0.8238316587559118, 0.7554341823322803, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1157 \tConstructive ( 718 ) \tNon constructive ( 439 )\n",
      "Accuracy:  0.6568712186689715\n",
      "Precision-recall for each class:  (array([0.13439636, 0.97632312]), array([0.77631579, 0.64847364]), array([0.22912621, 0.77932185]), array([  76, 1081]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.78      0.13      0.23       439\n",
      "    constructive       0.65      0.98      0.78       718\n",
      "\n",
      "     avg / total       0.70      0.66      0.57      1157\n",
      "\n",
      "Results: \n",
      "micro_average => (0.6568712186689715, 0.6568712186689715, 0.6568712186689715, None)\n",
      "weighted_average => (0.9210193737994317, 0.6568712186689715, 0.7431810779479354, None)\n",
      "macro_average => (0.555359737565117, 0.7123947124981742, 0.5042240295309692, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  303 \tConstructive ( 261 ) \tNon constructive ( 42 )\n",
      "Accuracy:  0.7821782178217822\n",
      "Precision-recall for each class:  (array([0.        , 0.90804598]), array([0.        , 0.84946237]), array([0.        , 0.87777778]), array([ 24, 279]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        42\n",
      "    constructive       0.85      0.91      0.88       261\n",
      "\n",
      "     avg / total       0.73      0.78      0.76       303\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7821782178217822, 0.7821782178217822, 0.7821782178217822, None)\n",
      "weighted_average => (0.8361215431888016, 0.7821782178217822, 0.8082508250825083, None)\n",
      "macro_average => (0.4540229885057471, 0.42473118279569894, 0.43888888888888894, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  2\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10376\n",
      "Test samples:  2659\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4705 \tConstructive ( 2832 ) \tNon constructive ( 1873 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1222 \tConstructive ( 1033 ) \tNon constructive ( 189 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1238 \tConstructive ( 723 ) \tNon constructive ( 515 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  303 \tConstructive ( 259 ) \tNon constructive ( 44 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats']\n",
      "Size of the training data:  10376 \tConstructive ( 5152 ) \tNon constructive ( 5224 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2659 \tConstructive ( 1305 ) \tNon constructive ( 1354 )\n",
      "Accuracy:  0.7401278676194057\n",
      "Precision-recall for each class:  (array([0.50738552, 0.9816092 ]), array([0.96624473, 0.65759754]), array([0.6653753 , 0.78758069]), array([ 711, 1948]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.97      0.51      0.67      1354\n",
      "    constructive       0.66      0.98      0.79      1305\n",
      "\n",
      "     avg / total       0.81      0.74      0.73      2659\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7401278676194057, 0.7401278676194057, 0.7401278676194057, None)\n",
      "weighted_average => (0.8548047463228032, 0.7401278676194057, 0.7549037358231214, None)\n",
      "macro_average => (0.7444973598872646, 0.8119211308363441, 0.726477998703376, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1238 \tConstructive ( 723 ) \tNon constructive ( 515 )\n",
      "Accuracy:  0.6211631663974152\n",
      "Precision-recall for each class:  (array([0.11262136, 0.98340249]), array([0.82857143, 0.60873288]), array([0.1982906 , 0.75198308]), array([  70, 1168]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.83      0.11      0.20       515\n",
      "    constructive       0.61      0.98      0.75       723\n",
      "\n",
      "     avg / total       0.70      0.62      0.52      1238\n",
      "\n",
      "Results: \n",
      "micro_average => (0.6211631663974152, 0.6211631663974152, 0.6211631663974152, None)\n",
      "weighted_average => (0.934166076760459, 0.6211631663974152, 0.7206757485272584, None)\n",
      "macro_average => (0.5480119244249284, 0.7186521526418788, 0.4751368380136227, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  303 \tConstructive ( 259 ) \tNon constructive ( 44 )\n",
      "Accuracy:  0.7821782178217822\n",
      "Precision-recall for each class:  (array([0.        , 0.91505792]), array([0.        , 0.84341637]), array([0.        , 0.87777778]), array([ 22, 281]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        44\n",
      "    constructive       0.84      0.92      0.88       259\n",
      "\n",
      "     avg / total       0.72      0.78      0.75       303\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7821782178217822, 0.7821782178217822, 0.7821782178217822, None)\n",
      "weighted_average => (0.8486180664398485, 0.7821782178217821, 0.8140447378071142, None)\n",
      "macro_average => (0.4575289575289575, 0.42170818505338076, 0.43888888888888894, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  3\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10438\n",
      "Test samples:  2597\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4800 \tConstructive ( 2880 ) \tNon constructive ( 1920 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1230 \tConstructive ( 1047 ) \tNon constructive ( 183 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1143 \tConstructive ( 675 ) \tNon constructive ( 468 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  295 \tConstructive ( 245 ) \tNon constructive ( 50 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats']\n",
      "Size of the training data:  10438 \tConstructive ( 5189 ) \tNon constructive ( 5249 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2597 \tConstructive ( 1268 ) \tNon constructive ( 1329 )\n",
      "Accuracy:  0.7443203696572969\n",
      "Precision-recall for each class:  (array([0.5131678 , 0.98659306]), array([0.97567954, 0.65911486]), array([0.67258383, 0.79027164]), array([ 699, 1898]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.98      0.51      0.67      1329\n",
      "    constructive       0.66      0.99      0.79      1268\n",
      "\n",
      "     avg / total       0.82      0.74      0.73      2597\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7443203696572969, 0.7443203696572969, 0.7443203696572969, None)\n",
      "weighted_average => (0.8591674688869095, 0.7443203696572969, 0.7585951713734086, None)\n",
      "macro_average => (0.7498804276358734, 0.817397199974071, 0.7314277312819516, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1143 \tConstructive ( 675 ) \tNon constructive ( 468 )\n",
      "Accuracy:  0.6290463692038495\n",
      "Precision-recall for each class:  (array([0.11111111, 0.98814815]), array([0.86666667, 0.61588181]), array([0.1969697 , 0.75881684]), array([  60, 1083]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.87      0.11      0.20       468\n",
      "    constructive       0.62      0.99      0.76       675\n",
      "\n",
      "     avg / total       0.72      0.63      0.53      1143\n",
      "\n",
      "Results: \n",
      "micro_average => (0.6290463692038495, 0.6290463692038495, 0.6290463692038495, None)\n",
      "weighted_average => (0.9421094585399047, 0.6290463692038495, 0.7293235491080214, None)\n",
      "macro_average => (0.5496296296296296, 0.7412742382271469, 0.47789326714241387, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  295 \tConstructive ( 245 ) \tNon constructive ( 50 )\n",
      "Accuracy:  0.7762711864406779\n",
      "Precision-recall for each class:  (array([0.        , 0.93469388]), array([0.        , 0.82078853]), array([0.       , 0.8740458]), array([ 16, 279]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        50\n",
      "    constructive       0.82      0.93      0.87       245\n",
      "\n",
      "     avg / total       0.68      0.78      0.73       295\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7762711864406779, 0.7762711864406779, 0.7762711864406779, None)\n",
      "weighted_average => (0.8839986163957109, 0.7762711864406779, 0.8266399275456076, None)\n",
      "macro_average => (0.4673469387755102, 0.4103942652329749, 0.4370229007633588, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  4\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10481\n",
      "Test samples:  2554\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4819 \tConstructive ( 2887 ) \tNon constructive ( 1932 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1234 \tConstructive ( 1044 ) \tNon constructive ( 190 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1124 \tConstructive ( 668 ) \tNon constructive ( 456 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  291 \tConstructive ( 248 ) \tNon constructive ( 43 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats']\n",
      "Size of the training data:  10481 \tConstructive ( 5233 ) \tNon constructive ( 5248 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2554 \tConstructive ( 1224 ) \tNon constructive ( 1330 )\n",
      "Accuracy:  0.7466718872357087\n",
      "Precision-recall for each class:  (array([0.52631579, 0.98611111]), array([0.9762901 , 0.65704954]), array([0.6839277 , 0.78863117]), array([ 717, 1837]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.98      0.53      0.68      1330\n",
      "    constructive       0.66      0.99      0.79      1224\n",
      "\n",
      "     avg / total       0.82      0.75      0.73      2554\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7466718872357087, 0.7466718872357087, 0.7466718872357087, None)\n",
      "weighted_average => (0.8570299656083566, 0.7466718872357087, 0.7592371232188738, None)\n",
      "macro_average => (0.7562134502923976, 0.816669817459034, 0.7362794326786699, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1124 \tConstructive ( 668 ) \tNon constructive ( 456 )\n",
      "Accuracy:  0.6290035587188612\n",
      "Precision-recall for each class:  (array([0.10526316, 0.98652695]), array([0.84210526, 0.61761949]), array([0.1871345 , 0.75965418]), array([  57, 1067]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.84      0.11      0.19       456\n",
      "    constructive       0.62      0.99      0.76       668\n",
      "\n",
      "     avg / total       0.71      0.63      0.53      1124\n",
      "\n",
      "Results: \n",
      "micro_average => (0.6290035587188612, 0.6290035587188612, 0.6290035587188612, None)\n",
      "weighted_average => (0.9418365226841691, 0.6290035587188612, 0.7306207075731315, None)\n",
      "macro_average => (0.5458950520012606, 0.7298623785330243, 0.4733943407991641, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  291 \tConstructive ( 248 ) \tNon constructive ( 43 )\n",
      "Accuracy:  0.8075601374570447\n",
      "Precision-recall for each class:  (array([0.        , 0.94758065]), array([0.        , 0.84532374]), array([0.        , 0.89353612]), array([ 13, 278]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        43\n",
      "    constructive       0.85      0.95      0.89       248\n",
      "\n",
      "     avg / total       0.72      0.81      0.76       291\n",
      "\n",
      "Results: \n",
      "micro_average => (0.8075601374570447, 0.8075601374570447, 0.8075601374570447, None)\n",
      "weighted_average => (0.9052488637623324, 0.8075601374570447, 0.8536187004298799, None)\n",
      "macro_average => (0.4737903225806452, 0.4226618705035971, 0.4467680608365019, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  5\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10483\n",
      "Test samples:  2552\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4814 \tConstructive ( 2898 ) \tNon constructive ( 1916 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1239 \tConstructive ( 1057 ) \tNon constructive ( 182 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1129 \tConstructive ( 657 ) \tNon constructive ( 472 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  286 \tConstructive ( 235 ) \tNon constructive ( 51 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats']\n",
      "Size of the training data:  10483 \tConstructive ( 5191 ) \tNon constructive ( 5292 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2552 \tConstructive ( 1266 ) \tNon constructive ( 1286 )\n",
      "Accuracy:  0.752742946708464\n",
      "Precision-recall for each class:  (array([0.52410575, 0.9849921 ]), array([0.97258297, 0.67079075]), array([0.6811521, 0.79808  ]), array([ 693, 1859]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.97      0.52      0.68      1286\n",
      "    constructive       0.67      0.98      0.80      1266\n",
      "\n",
      "     avg / total       0.82      0.75      0.74      2552\n",
      "\n",
      "Results: \n",
      "micro_average => (0.752742946708464, 0.752742946708464, 0.7527429467084639, None)\n",
      "weighted_average => (0.8598376189927929, 0.752742946708464, 0.7663280263455943, None)\n",
      "macro_average => (0.7545489276913363, 0.8216868601483986, 0.7396160485093481, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1129 \tConstructive ( 657 ) \tNon constructive ( 472 )\n",
      "Accuracy:  0.6182462356067316\n",
      "Precision-recall for each class:  (array([0.10169492, 0.98934551]), array([0.87272727, 0.60521415]), array([0.18216319, 0.75101098]), array([  55, 1074]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.87      0.10      0.18       472\n",
      "    constructive       0.61      0.99      0.75       657\n",
      "\n",
      "     avg / total       0.72      0.62      0.51      1129\n",
      "\n",
      "Results: \n",
      "micro_average => (0.6182462356067316, 0.6182462356067316, 0.6182462356067316, None)\n",
      "weighted_average => (0.9461030097117392, 0.6182462356067316, 0.7232991708534929, None)\n",
      "macro_average => (0.5455202125738462, 0.7389707127137295, 0.46658708208502836, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  286 \tConstructive ( 235 ) \tNon constructive ( 51 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7657342657342657\n",
      "Precision-recall for each class:  (array([0.        , 0.93191489]), array([0.        , 0.81111111]), array([0.        , 0.86732673]), array([ 16, 270]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.00      0.00      0.00        51\n",
      "    constructive       0.81      0.93      0.87       235\n",
      "\n",
      "     avg / total       0.67      0.77      0.71       286\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7657342657342657, 0.7657342657342657, 0.7657342657342657, None)\n",
      "weighted_average => (0.8797797946734117, 0.7657342657342657, 0.8188049574188186, None)\n",
      "macro_average => (0.46595744680851064, 0.40555555555555556, 0.4336633663366336, None)\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "feature_set = text_feats\n",
    "avg_results_text_dict = run_n_experiments(all_SOCC_df, feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>test_all</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.818301</td>\n",
       "      <td>0.737847</td>\n",
       "      <td>0.754739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.749786</td>\n",
       "      <td>0.749786</td>\n",
       "      <td>0.749786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.749786</td>\n",
       "      <td>0.762913</td>\n",
       "      <td>0.857338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_balanced</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.728231</td>\n",
       "      <td>0.479447</td>\n",
       "      <td>0.548883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.630866</td>\n",
       "      <td>0.630866</td>\n",
       "      <td>0.630866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.630866</td>\n",
       "      <td>0.729420</td>\n",
       "      <td>0.937047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>test_hard</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_P</th>\n",
       "      <th>mean_F1</th>\n",
       "      <th>mean_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.417010</td>\n",
       "      <td>0.439046</td>\n",
       "      <td>0.463729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_average</th>\n",
       "      <td>0.782784</td>\n",
       "      <td>0.782784</td>\n",
       "      <td>0.782784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.782784</td>\n",
       "      <td>0.824272</td>\n",
       "      <td>0.870753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretty_print_results(avg_results_text_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only non length features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  1\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10437\n",
      "Test samples:  2598\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4720 \tConstructive ( 2834 ) \tNon constructive ( 1886 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1202 \tConstructive ( 1015 ) \tNon constructive ( 187 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1223 \tConstructive ( 721 ) \tNon constructive ( 502 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  323 \tConstructive ( 277 ) \tNon constructive ( 46 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  10437 \tConstructive ( 5172 ) \tNon constructive ( 5265 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2598 \tConstructive ( 1285 ) \tNon constructive ( 1313 )\n",
      "Accuracy:  0.876058506543495\n",
      "Precision-recall for each class:  (array([0.85072353, 0.90194553]), array([0.89863234, 0.85535055]), array([0.87402191, 0.8780303 ]), array([1243, 1355]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.90      0.85      0.87      1313\n",
      "    constructive       0.86      0.90      0.88      1285\n",
      "\n",
      "     avg / total       0.88      0.88      0.88      2598\n",
      "\n",
      "Results: \n",
      "micro_average => (0.876058506543495, 0.876058506543495, 0.876058506543495, None)\n",
      "weighted_average => (0.8774386217852189, 0.876058506543495, 0.8761125072297535, None)\n",
      "macro_average => (0.8763345295918398, 0.8769914473078761, 0.87602610613174, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1223 \tConstructive ( 721 ) \tNon constructive ( 502 )\n",
      "Accuracy:  0.7694194603434178\n",
      "Precision-recall for each class:  (array([0.65936255, 0.84604716]), array([0.74886878, 0.78104994]), array([0.70127119, 0.81225033]), array([442, 781]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.75      0.66      0.70       502\n",
      "    constructive       0.78      0.85      0.81       721\n",
      "\n",
      "     avg / total       0.77      0.77      0.77      1223\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7694194603434178, 0.7694194603434178, 0.7694194603434178, None)\n",
      "weighted_average => (0.7785781491541768, 0.7694194603434178, 0.7721417615645659, None)\n",
      "macro_average => (0.7527048532637826, 0.7649593571300282, 0.7567607596650794, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  323 \tConstructive ( 277 ) \tNon constructive ( 46 )\n",
      "Accuracy:  0.5975232198142415\n",
      "Precision-recall for each class:  (array([0.13043478, 0.67509025]), array([0.0625    , 0.82378855]), array([0.08450704, 0.74206349]), array([ 96, 227]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.06      0.13      0.08        46\n",
      "    constructive       0.82      0.68      0.74       277\n",
      "\n",
      "     avg / total       0.72      0.60      0.65       323\n",
      "\n",
      "Results: \n",
      "micro_average => (0.5975232198142415, 0.5975232198142415, 0.5975232198142415, None)\n",
      "weighted_average => (0.5132112275388722, 0.5975232198142415, 0.5466287577546463, None)\n",
      "macro_average => (0.4027625176581385, 0.4431442731277533, 0.4132852671585066, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  2\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10518\n",
      "Test samples:  2517\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4796 \tConstructive ( 2871 ) \tNon constructive ( 1925 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1227 \tConstructive ( 1041 ) \tNon constructive ( 186 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1147 \tConstructive ( 684 ) \tNon constructive ( 463 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  298 \tConstructive ( 251 ) \tNon constructive ( 47 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  10518 \tConstructive ( 5196 ) \tNon constructive ( 5322 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2517 \tConstructive ( 1261 ) \tNon constructive ( 1256 )\n",
      "Accuracy:  0.8792212951926897\n",
      "Precision-recall for each class:  (array([0.84633758, 0.91197462]), array([0.90545145, 0.85629188]), array([0.87489712, 0.88325653]), array([1174, 1343]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.85      0.87      1256\n",
      "    constructive       0.86      0.91      0.88      1261\n",
      "\n",
      "     avg / total       0.88      0.88      0.88      2517\n",
      "\n",
      "Results: \n",
      "micro_average => (0.8792212951926897, 0.8792212951926897, 0.8792212951926897, None)\n",
      "weighted_average => (0.8813596494172243, 0.8792212951926897, 0.8793574635566653, None)\n",
      "macro_average => (0.8791561014663319, 0.8808716659415152, 0.8790768238796913, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1147 \tConstructive ( 684 ) \tNon constructive ( 463 )\n",
      "Accuracy:  0.7724498692240628\n",
      "Precision-recall for each class:  (array([0.63066955, 0.86842105]), array([0.76439791, 0.77647059]), array([0.69112426, 0.81987578]), array([382, 765]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.76      0.63      0.69       463\n",
      "    constructive       0.78      0.87      0.82       684\n",
      "\n",
      "     avg / total       0.77      0.77      0.77      1147\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7724498692240628, 0.7724498692240628, 0.7724498692240628, None)\n",
      "weighted_average => (0.7892396442910365, 0.7724498692240628, 0.7769960212726423, None)\n",
      "macro_average => (0.749545299533932, 0.7704342469972283, 0.7555000183762726, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  298 \tConstructive ( 251 ) \tNon constructive ( 47 )\n",
      "Accuracy:  0.5771812080536913\n",
      "Precision-recall for each class:  (array([0.04255319, 0.67729084]), array([0.02409639, 0.79069767]), array([0.03076923, 0.72961373]), array([ 83, 215]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.02      0.04      0.03        47\n",
      "    constructive       0.79      0.68      0.73       251\n",
      "\n",
      "     avg / total       0.67      0.58      0.62       298\n",
      "\n",
      "Results: \n",
      "micro_average => (0.5771812080536913, 0.5771812080536913, 0.5771812080536913, None)\n",
      "weighted_average => (0.5005014925305206, 0.5771812080536913, 0.5349691239716299, None)\n",
      "macro_average => (0.35992201407137403, 0.4073970299803866, 0.380191482337405, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  3\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10401\n",
      "Test samples:  2634\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4764 \tConstructive ( 2840 ) \tNon constructive ( 1924 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1212 \tConstructive ( 1028 ) \tNon constructive ( 184 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1179 \tConstructive ( 715 ) \tNon constructive ( 464 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  313 \tConstructive ( 264 ) \tNon constructive ( 49 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  10401 \tConstructive ( 5138 ) \tNon constructive ( 5263 )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2634 \tConstructive ( 1319 ) \tNon constructive ( 1315 )\n",
      "Accuracy:  0.880030372057707\n",
      "Precision-recall for each class:  (array([0.84790875, 0.91205459]), array([0.90576767, 0.85744833]), array([0.87588374, 0.88390889]), array([1231, 1403]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.91      0.85      0.88      1315\n",
      "    constructive       0.86      0.91      0.88      1319\n",
      "\n",
      "     avg / total       0.88      0.88      0.88      2634\n",
      "\n",
      "Results: \n",
      "micro_average => (0.880030372057707, 0.880030372057707, 0.880030372057707, None)\n",
      "weighted_average => (0.8820760253193347, 0.880030372057707, 0.8801583357462275, None)\n",
      "macro_average => (0.8799816660276683, 0.8816079967899818, 0.8798963148602091, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1179 \tConstructive ( 715 ) \tNon constructive ( 464 )\n",
      "Accuracy:  0.7701441899915182\n",
      "Precision-recall for each class:  (array([0.62715517, 0.86293706]), array([0.74807198, 0.78101266]), array([0.68229777, 0.81993355]), array([389, 790]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.75      0.63      0.68       464\n",
      "    constructive       0.78      0.86      0.82       715\n",
      "\n",
      "     avg / total       0.77      0.77      0.77      1179\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7701441899915182, 0.7701441899915182, 0.7701441899915182, None)\n",
      "weighted_average => (0.7851430379891817, 0.7701441899915182, 0.7745219184345803, None)\n",
      "macro_average => (0.745046117675428, 0.7645423188311478, 0.7511156636923426, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  313 \tConstructive ( 264 ) \tNon constructive ( 49 )\n",
      "Accuracy:  0.5910543130990416\n",
      "Precision-recall for each class:  (array([0.12244898, 0.6780303 ]), array([0.06593407, 0.80630631]), array([0.08571429, 0.73662551]), array([ 91, 222]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.07      0.12      0.09        49\n",
      "    constructive       0.81      0.68      0.74       264\n",
      "\n",
      "     avg / total       0.69      0.59      0.63       313\n",
      "\n",
      "Results: \n",
      "micro_average => (0.5910543130990416, 0.5910543130990416, 0.5910543130990416, None)\n",
      "weighted_average => (0.5165034645865316, 0.5910543130990416, 0.5473829527077664, None)\n",
      "macro_average => (0.40023964131106987, 0.4361201861201861, 0.41116990005878895, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  4\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10438\n",
      "Test samples:  2597\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4767 \tConstructive ( 2861 ) \tNon constructive ( 1906 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1215 \tConstructive ( 1024 ) \tNon constructive ( 191 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1176 \tConstructive ( 694 ) \tNon constructive ( 482 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  310 \tConstructive ( 268 ) \tNon constructive ( 42 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  10438 \tConstructive ( 5160 ) \tNon constructive ( 5278 )\n",
      "Model trained and pickled in file:  /home/vkolhatk/data/Constructiveness_public/models/tmp_model.pkl\n",
      "\n",
      "TESTING ON ALL TEST SAMPLES\n",
      "\n",
      "Size of the data:  2597 \tConstructive ( 1297 ) \tNon constructive ( 1300 )\n",
      "Accuracy:  0.8733153638814016\n",
      "Precision-recall for each class:  (array([0.84846154, 0.89822668]), array([0.89311741, 0.85535977]), array([0.87021696, 0.87626927]), array([1235, 1362]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.89      0.85      0.87      1300\n",
      "    constructive       0.86      0.90      0.88      1297\n",
      "\n",
      "     avg / total       0.87      0.87      0.87      2597\n",
      "\n",
      "Results: \n",
      "micro_average => (0.8733153638814016, 0.8733153638814016, 0.8733153638814016, None)\n",
      "weighted_average => (0.8745609295346716, 0.8733153638814016, 0.8733911051706792, None)\n",
      "macro_average => (0.8733441077041695, 0.8742385869791388, 0.8732431183439371, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON BALANCED TEST SAMPLES\n",
      "\n",
      "Size of the data:  1176 \tConstructive ( 694 ) \tNon constructive ( 482 )\n",
      "Accuracy:  0.7559523809523809\n",
      "Precision-recall for each class:  (array([0.64522822, 0.83285303]), array([0.72833724, 0.77169559]), array([0.68426843, 0.8011088 ]), array([427, 749]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.73      0.65      0.68       482\n",
      "    constructive       0.77      0.83      0.80       694\n",
      "\n",
      "     avg / total       0.75      0.76      0.75      1176\n",
      "\n",
      "Results: \n",
      "micro_average => (0.7559523809523809, 0.7559523809523809, 0.7559523809523809, None)\n",
      "weighted_average => (0.7647273508157254, 0.7559523809523809, 0.7586846175955086, None)\n",
      "macro_average => (0.7390406208521172, 0.7500164153297293, 0.7426886139757427, None)\n",
      "<class 'dict'>\n",
      "\n",
      "TESTING ON HARD TEST SAMPLES\n",
      "\n",
      "Size of the data:  310 \tConstructive ( 268 ) \tNon constructive ( 42 )\n",
      "Accuracy:  0.603225806451613\n",
      "Precision-recall for each class:  (array([0.19047619, 0.66791045]), array([0.08247423, 0.84037559]), array([0.11510791, 0.74428274]), array([ 97, 213]))\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "non-constructive       0.08      0.19      0.12        42\n",
      "    constructive       0.84      0.67      0.74       268\n",
      "\n",
      "     avg / total       0.74      0.60      0.66       310\n",
      "\n",
      "Results: \n",
      "micro_average => (0.603225806451613, 0.603225806451613, 0.603225806451613, None)\n",
      "weighted_average => (0.5185197285462091, 0.603225806451613, 0.5474119101874962, None)\n",
      "macro_average => (0.42919331911869224, 0.46142490682929194, 0.42969532897590457, None)\n",
      "<class 'dict'>\n",
      "\n",
      "-----------------------------\n",
      "EXPERIMENT:  5\n",
      "-----------------------------\n",
      "\n",
      "Training samples:  10408\n",
      "Test samples:  2627\n",
      "\n",
      "TRAIN SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  4702 \tConstructive ( 2807 ) \tNon constructive ( 1895 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  1218 \tConstructive ( 1034 ) \tNon constructive ( 184 )\n",
      "None\n",
      "\n",
      "TEST SET DISTRIBUTIONS: \n",
      "Distribution in balanced samples: \n",
      "Size of the data:  1241 \tConstructive ( 748 ) \tNon constructive ( 493 )\n",
      "None\n",
      "Distribution in hard samples: \n",
      "Size of the data:  307 \tConstructive ( 258 ) \tNon constructive ( 49 )\n",
      "None\n",
      "\n",
      "TRAINING...\n",
      "\n",
      "Classifier:  SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=42, shuffle=True,\n",
      "       tol=0.0001, verbose=0, warm_start=False)\n",
      "Feature set:  ['text_feats', 'perspective_content_value_feats', 'perspective_aggressiveness_feats', 'perspecitive_toxicity_feats']\n",
      "Size of the training data:  10408 \tConstructive ( 5155 ) \tNon constructive ( 5253 )\n"
     ]
    }
   ],
   "source": [
    "feature_set = text_feats + perspective_feats\n",
    "avg_results_non_len_dict = run_n_experiments(all_SOCC_df, feature_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print_results(avg_results_non_len_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = all_feats\n",
    "avg_results_all_dict = run_n_experiments(all_SOCC_df, feature_set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_print_results(avg_results_all_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set = create_numeric_representation_of_text_and_labels(test_set_df,\n",
    "#                                                             text_col = 'pp_comment_text',\n",
    "#                                                             target_col = 'constructive')\n",
    "#trainX, trainY, validationX, validationY = get_preprocessed_and_padded_train_validation_splits(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bilstm_classifier = BiLSTMConstructivenessClassifier(mode = 'test', model_path = Config.BILSTM_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bilstm_classifier.predict(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
